{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://nextjournal.com/gkoehler/pytorch-mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import needed files and basic setup\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import data_gen2\n",
    "import tropical\n",
    "\n",
    "from ipywidgets import Output\n",
    "from IPython.display import display, Markdown, Latex, Math, clear_output\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "import math\n",
    "\n",
    "from cvxopt import solvers, matrix\n",
    "\n",
    "import time\n",
    "\n",
    "%matplotlib notebook\n",
    "#plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f3e880b6b90>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "n_epochs = 3\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 100\n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load training and testing sets\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('files/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('files/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "network = Net()\n",
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_acc = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_acc = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    network.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = network(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct = pred.eq(target.data.view_as(pred)).sum()\n",
    "            \n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tAccuracy: {:.6f}'.format(\n",
    "                  epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                  100. * batch_idx / len(train_loader), loss.item(), 100. * correct / 64))\n",
    "            \n",
    "            train_losses.append(loss.item())\n",
    "            train_acc.append(100. * correct / 64)\n",
    "            train_counter.append((batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    network.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = network(data)\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "    test_acc.append(100. * correct / len(test_loader.dataset))\n",
    "    print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "          test_loss, correct, len(test_loader.dataset),\n",
    "          100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ben/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  if sys.path[0] == '':\n",
      "/home/ben/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 2.3197, Accuracy: 921/10000 (9%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.295876\tAccuracy: 7.000000\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.717218\tAccuracy: 85.000000\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.648279\tAccuracy: 78.000000\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.780567\tAccuracy: 76.000000\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.578907\tAccuracy: 84.000000\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.301817\tAccuracy: 92.000000\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.410833\tAccuracy: 89.000000\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.130464\tAccuracy: 98.000000\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.266642\tAccuracy: 89.000000\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.342565\tAccuracy: 89.000000\n",
      "\n",
      "Test set: Avg. loss: 0.2731, Accuracy: 9240/10000 (92%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.328436\tAccuracy: 87.000000\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.375078\tAccuracy: 87.000000\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.368630\tAccuracy: 90.000000\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.405410\tAccuracy: 89.000000\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.558067\tAccuracy: 84.000000\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.433948\tAccuracy: 85.000000\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.399698\tAccuracy: 85.000000\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.295139\tAccuracy: 90.000000\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.429343\tAccuracy: 87.000000\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.320988\tAccuracy: 87.000000\n",
      "\n",
      "Test set: Avg. loss: 0.2078, Accuracy: 9387/10000 (93%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.272215\tAccuracy: 89.000000\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.360614\tAccuracy: 92.000000\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.238639\tAccuracy: 92.000000\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.282120\tAccuracy: 92.000000\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.265263\tAccuracy: 85.000000\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.246575\tAccuracy: 89.000000\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.121977\tAccuracy: 96.000000\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.279869\tAccuracy: 93.000000\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.152855\tAccuracy: 96.000000\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.356476\tAccuracy: 89.000000\n",
      "\n",
      "Test set: Avg. loss: 0.1739, Accuracy: 9491/10000 (94%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "test()\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fig = plt.figure()\n",
    "# plt.plot(train_counter, train_acc, color='blue')\n",
    "# plt.plot(test_counter, test_acc, 'o', color='red')\n",
    "# plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
    "# plt.xlabel('number of training examples seen')\n",
    "# plt.ylabel('negative log likelihood loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = []\n",
    "for param in network.parameters():\n",
    "    params.append(param.detach().numpy())\n",
    "\n",
    "A1 = params[0]\n",
    "b1 = params[1]\n",
    "A2 = params[2][0,:].reshape((1, -1))\n",
    "b2 = params[3][:1]\n",
    "\n",
    "#Fterms, Gterms = tropical.getTropCoeffs(A1, b1, A2, b2, doTime=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Ftermsfull = []\n",
    "Gtermsfull = []\n",
    "for i in range(0, np.size(A1, axis = 0), 10):\n",
    "    Fterms, Gterms = tropical.getTropCoeffs(A1[i:i+10, :], b1[i:i+10], A2[:, i:i+10], b2)\n",
    "    Ftermsfull.append(Fterms)\n",
    "    Gtermsfull.append(Gterms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 32\n",
      "8 128\n",
      "32 32\n",
      "128 8\n",
      "64 16\n",
      "32 32\n",
      "16 64\n",
      "16 64\n",
      "16 64\n",
      "32 32\n",
      "4 256\n",
      "8 128\n",
      "16 16\n",
      "57.0 71.0\n"
     ]
    }
   ],
   "source": [
    "prodF = 1\n",
    "prodG = 1\n",
    "for i in range(len(Ftermsfull)):\n",
    "    print(len(Ftermsfull[i]), len(Gtermsfull[i]))\n",
    "    prodF *= len(Ftermsfull[i])\n",
    "    prodG *= len(Gtermsfull[i])\n",
    "    \n",
    "print(math.log(prodF, 2), math.log(prodG, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multiplyTrops(trop1, trop2):\n",
    "    temp = trop1 + trop2[0, :]\n",
    "    for i in range(1, trop2.shape[0]):\n",
    "        temp = np.vstack((temp, trop1 + trop2[i, :]))\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "solvers.options['show_progress'] = False\n",
    "def computeW(i, k, lam, gam, nbrs, temp):\n",
    "    _, indices = nbrs.kneighbors(temp[i:i+1, :])\n",
    "    indices = indices[0,1:]\n",
    "    neighbors = temp[indices, :]\n",
    "\n",
    "    # Set up quadratic programming problem\n",
    "    Qtild = np.dot(temp[indices, :], temp[indices, :].T)\n",
    "    Etild = np.eye(k)\n",
    "    E = gam*np.bmat([[Etild, -Etild], [-Etild, Etild]])\n",
    "\n",
    "    A = np.ones((2*k, 1))\n",
    "    A[k:, :] = -1\n",
    "\n",
    "    G = -np.eye(2*k)\n",
    "    h = np.zeros((2*k, 1))\n",
    "\n",
    "    b = np.array([1.0]).reshape(1,1)\n",
    "    Q = np.bmat([[Qtild, -Qtild], [-Qtild, Qtild]]) + E\n",
    "    \n",
    "    c = np.dot(temp[indices, :], temp[i, :])\n",
    "    c = c.reshape(-1, 1)\n",
    "    c = np.bmat([[-c], [c]]) + lam\n",
    "    \n",
    "    # Solve quadratic programming problem\n",
    "    out = solvers.qp(matrix(Q), matrix(c), matrix(G), matrix(h), matrix(A.T), matrix(b))\n",
    "    \n",
    "    # If there are negative weight values, it's near the convex hull\n",
    "    w = np.array(out['x'])[:k] - np.array(out['x'])[k:]\n",
    "    return w\n",
    "\n",
    "def computeWs(points, k=1000, lam=1e-3, gam=1e-6):\n",
    "    # Rescale points to roughly 0 to 1\n",
    "    shift = np.amin(points)\n",
    "    points = points - shift\n",
    "    scale = np.amax(points)\n",
    "    points = points/scale\n",
    "    nbrs = NearestNeighbors(n_neighbors=k+1).fit(points)\n",
    "    goodIndices = []\n",
    "    ws = np.zeros((points.shape[0], k))\n",
    "\n",
    "    start = time.time()\n",
    "    end = points.shape[0]\n",
    "    for i in range(end):\n",
    "        w = computeW(i, k, lam, gam, nbrs, points)\n",
    "        ws[i, :] = w.T\n",
    "        if np.sum(w < 0) > 0:\n",
    "            goodIndices.append(i)\n",
    "        if (i+1) % 100 == 0 or i+1 == end or i == 0:\n",
    "            print('i = {}/{}\\tverts={}\\ttime={}'.format(i+1, end, len(goodIndices), time.time()-start))\n",
    "            \n",
    "    return ws, goodIndices\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "def computeWsParallel(points, k=1000, lam=1e-3, gam=1e-6):\n",
    "    shift = np.amin(points)\n",
    "    points = points - shift\n",
    "    scale = np.amax(points)\n",
    "    points = points/scale\n",
    "    nbrs = NearestNeighbors(n_neighbors=k+1).fit(points)\n",
    "    goodIndices = []\n",
    "    ws = np.zeros((points.shape[0], k))\n",
    "\n",
    "    start = time.time()\n",
    "    end = points.shape[0]\n",
    "    for i in range(0, end, 100):\n",
    "        wsT = Parallel(n_jobs=4)(delayed(computeW)(i, k, lam, gam, nbrs, points) for i in range(i, max(i+100, end)))\n",
    "        for j in range(len(wsT)):\n",
    "            ws[i, :] = wsT[j].T\n",
    "            if np.sum(wsT[j] < 0) > 0:\n",
    "                goodIndices.append(i + j)\n",
    "            print('i = {}/{}\\tverts={}\\ttime={}'.format(i+j+1, end, len(goodIndices), time.time()-start))\n",
    "            \n",
    "    return ws, goodIndices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from joblib import Parallel, delayed\n",
    "# start = time.time()\n",
    "# ws = Parallel(n_jobs=4)(delayed(computeW)(i) for i in range(16))\n",
    "# print(start - time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 1/256\tverts=1\ttime=0.13802289962768555\n",
      "i = 100/256\tverts=100\ttime=10.865399837493896\n",
      "i = 200/256\tverts=200\ttime=21.694053173065186\n",
      "i = 256/256\tverts=256\ttime=27.740741729736328\n",
      "i = 1/4096\tverts=1\ttime=3.161743640899658\n",
      "i = 100/4096\tverts=100\ttime=333.84939908981323\n",
      "i = 200/4096\tverts=200\ttime=675.5911660194397\n",
      "i = 300/4096\tverts=300\ttime=1008.7682416439056\n",
      "i = 400/4096\tverts=400\ttime=1343.7411675453186\n",
      "i = 500/4096\tverts=500\ttime=1678.43390417099\n",
      "i = 600/4096\tverts=600\ttime=2010.0175104141235\n",
      "i = 700/4096\tverts=700\ttime=2335.753485441208\n",
      "i = 800/4096\tverts=800\ttime=2655.792400598526\n",
      "i = 900/4096\tverts=900\ttime=3001.0851793289185\n",
      "i = 1000/4096\tverts=1000\ttime=3330.0499637126923\n",
      "i = 1100/4096\tverts=1100\ttime=3664.6881988048553\n",
      "i = 1200/4096\tverts=1200\ttime=4005.0956881046295\n",
      "i = 1300/4096\tverts=1300\ttime=4342.645967245102\n",
      "i = 1400/4096\tverts=1400\ttime=4685.877069711685\n",
      "i = 1500/4096\tverts=1500\ttime=5022.865285158157\n",
      "i = 1600/4096\tverts=1600\ttime=5357.232897281647\n",
      "i = 1700/4096\tverts=1700\ttime=5690.936310529709\n",
      "i = 1800/4096\tverts=1800\ttime=6027.047432899475\n",
      "i = 1900/4096\tverts=1900\ttime=6363.091267347336\n",
      "i = 2000/4096\tverts=2000\ttime=6688.152952432632\n",
      "i = 2100/4096\tverts=2100\ttime=7022.597391366959\n",
      "i = 2200/4096\tverts=2200\ttime=7354.391043424606\n",
      "i = 2300/4096\tverts=2300\ttime=7689.374687194824\n",
      "i = 2400/4096\tverts=2400\ttime=8015.742095947266\n",
      "i = 2500/4096\tverts=2500\ttime=8348.594959974289\n",
      "i = 2600/4096\tverts=2600\ttime=8690.7846326828\n",
      "i = 2700/4096\tverts=2700\ttime=9035.177171230316\n",
      "i = 2800/4096\tverts=2800\ttime=9380.963975906372\n",
      "i = 2900/4096\tverts=2900\ttime=9718.6030023098\n",
      "i = 3000/4096\tverts=3000\ttime=10052.57614660263\n",
      "i = 3100/4096\tverts=3100\ttime=10394.074100017548\n",
      "i = 3200/4096\tverts=3200\ttime=10724.434296369553\n",
      "i = 3300/4096\tverts=3300\ttime=11068.551793813705\n",
      "i = 3400/4096\tverts=3400\ttime=11407.00726890564\n",
      "i = 3500/4096\tverts=3500\ttime=11734.357407331467\n",
      "i = 3600/4096\tverts=3600\ttime=12068.8638753891\n",
      "i = 3700/4096\tverts=3700\ttime=12402.288619756699\n",
      "i = 3800/4096\tverts=3800\ttime=12746.964315414429\n",
      "i = 3900/4096\tverts=3900\ttime=13077.331311941147\n",
      "i = 4000/4096\tverts=4000\ttime=13402.951614141464\n",
      "i = 4096/4096\tverts=4096\ttime=13735.451295137405\n",
      "i = 1/2048\tverts=1\ttime=3.301081895828247\n",
      "i = 100/2048\tverts=100\ttime=314.9152662754059\n",
      "i = 200/2048\tverts=200\ttime=631.5016107559204\n",
      "i = 300/2048\tverts=300\ttime=953.7701163291931\n",
      "i = 400/2048\tverts=400\ttime=1278.489219903946\n",
      "i = 500/2048\tverts=500\ttime=1603.38432431221\n",
      "i = 600/2048\tverts=600\ttime=1928.8031301498413\n",
      "i = 700/2048\tverts=700\ttime=2251.35906124115\n",
      "i = 800/2048\tverts=800\ttime=2582.025454759598\n",
      "i = 900/2048\tverts=900\ttime=2898.238945245743\n",
      "i = 1000/2048\tverts=1000\ttime=3216.1479454040527\n",
      "i = 1100/2048\tverts=1100\ttime=3536.5547749996185\n",
      "i = 1200/2048\tverts=1200\ttime=3864.381634950638\n",
      "i = 1300/2048\tverts=1300\ttime=4193.638561248779\n",
      "i = 1400/2048\tverts=1400\ttime=4508.638322353363\n",
      "i = 1500/2048\tverts=1500\ttime=4826.967500448227\n",
      "i = 1600/2048\tverts=1600\ttime=5148.356994152069\n",
      "i = 1700/2048\tverts=1700\ttime=5472.931797504425\n",
      "i = 1800/2048\tverts=1800\ttime=5797.446597337723\n",
      "i = 1900/2048\tverts=1900\ttime=6130.341295003891\n",
      "i = 2000/2048\tverts=2000\ttime=6453.11553144455\n",
      "i = 2048/2048\tverts=2048\ttime=6614.961036682129\n",
      "i = 1/256\tverts=1\ttime=0.1083533763885498\n",
      "i = 100/256\tverts=100\ttime=11.040724754333496\n",
      "i = 200/256\tverts=200\ttime=22.0292706489563\n",
      "i = 256/256\tverts=256\ttime=28.1631121635437\n",
      "i = 1/512\tverts=1\ttime=0.4748189449310303\n",
      "i = 100/512\tverts=100\ttime=46.053672790527344\n",
      "i = 200/512\tverts=200\ttime=92.30127048492432\n",
      "i = 300/512\tverts=300\ttime=143.0072546005249\n",
      "i = 400/512\tverts=400\ttime=190.8970079421997\n",
      "i = 500/512\tverts=500\ttime=237.17046403884888\n",
      "i = 512/512\tverts=512\ttime=242.9915156364441\n",
      "i = 1/256\tverts=1\ttime=0.09840846061706543\n",
      "i = 100/256\tverts=84\ttime=9.791415214538574\n",
      "i = 200/256\tverts=176\ttime=19.534800052642822\n",
      "i = 256/256\tverts=224\ttime=25.354397535324097\n",
      "[256, 4096, 2048, 256, 512, 256]\n",
      "[256, 4096, 2048, 256, 512, 224]\n"
     ]
    }
   ],
   "source": [
    "newFterms = []\n",
    "goodIndicesFull = []\n",
    "fullWs = []\n",
    "for i in range(0, len(Ftermsfull)-1, 2):\n",
    "    tempAdd = np.array(list(Ftermsfull[i]))\n",
    "    tempAdd2 = np.array(list(Ftermsfull[i+1]))\n",
    "    temp = multiplyTrops(tempAdd, tempAdd2)\n",
    "    \n",
    "    # There may be an odd number of terms - in that case, wrap the last in with the previous 2\n",
    "    if len(Ftermsfull) - 1 <= i+2:\n",
    "        tempAdd2 = np.array(list(Ftermsfull[i+1]))\n",
    "        temp = multiplyTrops(temp, tempAdd2)\n",
    "    \n",
    "    newFterms.append(temp)\n",
    "    ws, goodIndices = computeWs(temp, k=min(1000, temp.shape[0]-1))\n",
    "    goodIndicesFull.append(goodIndices)\n",
    "    fullWs.append(ws)\n",
    "    \n",
    "print([val.shape[0] for val in newFterms])\n",
    "print([len(val) for val in goodIndicesFull])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 1/65536\tverts=1\ttime=3.182948589324951\n",
      "i = 100/65536\tverts=97\ttime=313.57209968566895\n",
      "i = 200/65536\tverts=193\ttime=626.9816176891327\n",
      "i = 300/65536\tverts=291\ttime=934.8976018428802\n",
      "i = 400/65536\tverts=385\ttime=1242.9539551734924\n",
      "i = 500/65536\tverts=485\ttime=1558.6873517036438\n",
      "i = 600/65536\tverts=582\ttime=1856.3139126300812\n",
      "i = 700/65536\tverts=677\ttime=2165.697219848633\n",
      "i = 800/65536\tverts=777\ttime=2468.375405550003\n",
      "i = 900/65536\tverts=871\ttime=2776.136768579483\n",
      "i = 1000/65536\tverts=969\ttime=3092.1326949596405\n",
      "i = 1100/65536\tverts=1006\ttime=3395.798807144165\n",
      "i = 1200/65536\tverts=1024\ttime=3698.798754930496\n",
      "i = 1300/65536\tverts=1034\ttime=3996.8488540649414\n",
      "i = 1400/65536\tverts=1054\ttime=4291.096279621124\n",
      "i = 1500/65536\tverts=1069\ttime=4595.8072056770325\n",
      "i = 1600/65536\tverts=1084\ttime=4886.637312173843\n",
      "i = 1700/65536\tverts=1102\ttime=5192.1670796871185\n",
      "i = 1800/65536\tverts=1113\ttime=5486.083515882492\n",
      "i = 1900/65536\tverts=1133\ttime=5793.051257133484\n",
      "i = 2000/65536\tverts=1147\ttime=6102.012113332748\n",
      "i = 2100/65536\tverts=1162\ttime=6403.886331319809\n",
      "i = 2200/65536\tverts=1190\ttime=6720.0117127895355\n",
      "i = 2300/65536\tverts=1217\ttime=7037.409576654434\n",
      "i = 2400/65536\tverts=1237\ttime=7356.41132068634\n",
      "i = 2500/65536\tverts=1261\ttime=7685.620229244232\n",
      "i = 2600/65536\tverts=1280\ttime=8002.65683054924\n",
      "i = 2700/65536\tverts=1294\ttime=8316.001665353775\n",
      "i = 2800/65536\tverts=1308\ttime=8644.028806447983\n",
      "i = 2900/65536\tverts=1323\ttime=8967.6842315197\n",
      "i = 3000/65536\tverts=1342\ttime=9289.023063898087\n",
      "i = 3100/65536\tverts=1362\ttime=9597.899817228317\n",
      "i = 3200/65536\tverts=1374\ttime=9902.148889780045\n",
      "i = 3300/65536\tverts=1391\ttime=10207.39233660698\n",
      "i = 3400/65536\tverts=1400\ttime=10506.531738519669\n",
      "i = 3500/65536\tverts=1417\ttime=10810.993475198746\n",
      "i = 3600/65536\tverts=1431\ttime=11118.215312957764\n",
      "i = 3700/65536\tverts=1436\ttime=11425.616429328918\n",
      "i = 3800/65536\tverts=1450\ttime=11722.476805448532\n",
      "i = 3900/65536\tverts=1458\ttime=12021.04776597023\n",
      "i = 4000/65536\tverts=1470\ttime=12329.532857656479\n",
      "i = 4100/65536\tverts=1484\ttime=12627.83437037468\n",
      "i = 4200/65536\tverts=1490\ttime=12952.117210388184\n",
      "i = 4300/65536\tverts=1498\ttime=13285.412496089935\n",
      "i = 4400/65536\tverts=1506\ttime=13626.55094575882\n",
      "i = 4500/65536\tverts=1511\ttime=13952.10518693924\n",
      "i = 4600/65536\tverts=1515\ttime=14281.383689880371\n",
      "i = 4700/65536\tverts=1519\ttime=14602.779606103897\n",
      "i = 4800/65536\tverts=1522\ttime=14922.242796182632\n",
      "i = 4900/65536\tverts=1527\ttime=15262.74932050705\n",
      "i = 5000/65536\tverts=1530\ttime=15588.78624176979\n",
      "i = 5100/65536\tverts=1537\ttime=15921.952005386353\n",
      "i = 5200/65536\tverts=1549\ttime=16231.744790792465\n",
      "i = 5300/65536\tverts=1555\ttime=16538.010786533356\n",
      "i = 5400/65536\tverts=1567\ttime=16837.961131572723\n",
      "i = 5500/65536\tverts=1582\ttime=17145.94645667076\n",
      "i = 5600/65536\tverts=1592\ttime=17446.789682388306\n",
      "i = 5700/65536\tverts=1602\ttime=17744.885725736618\n",
      "i = 5800/65536\tverts=1615\ttime=18038.30475473404\n",
      "i = 5900/65536\tverts=1624\ttime=18344.0272462368\n",
      "i = 6000/65536\tverts=1634\ttime=18655.98098397255\n",
      "i = 6100/65536\tverts=1640\ttime=18965.025939702988\n",
      "i = 6200/65536\tverts=1660\ttime=19269.376854896545\n",
      "i = 6300/65536\tverts=1693\ttime=19568.968683242798\n",
      "i = 6400/65536\tverts=1724\ttime=19868.618792295456\n",
      "i = 6500/65536\tverts=1757\ttime=20175.67886543274\n",
      "i = 6600/65536\tverts=1790\ttime=20480.287435293198\n",
      "i = 6700/65536\tverts=1823\ttime=20782.033583641052\n",
      "i = 6800/65536\tverts=1853\ttime=21087.418384313583\n",
      "i = 6900/65536\tverts=1882\ttime=21390.94526720047\n",
      "i = 7000/65536\tverts=1914\ttime=21691.45596933365\n",
      "i = 7100/65536\tverts=1947\ttime=21998.09913086891\n",
      "i = 7200/65536\tverts=1975\ttime=22301.79108762741\n",
      "i = 7300/65536\tverts=1988\ttime=22624.96816134453\n",
      "i = 7400/65536\tverts=2002\ttime=22965.927003383636\n",
      "i = 7500/65536\tverts=2012\ttime=23296.774227380753\n",
      "i = 7600/65536\tverts=2020\ttime=23616.774396896362\n",
      "i = 7700/65536\tverts=2023\ttime=23941.243718862534\n",
      "i = 7800/65536\tverts=2027\ttime=24271.653239250183\n",
      "i = 7900/65536\tverts=2031\ttime=24594.01334118843\n",
      "i = 8000/65536\tverts=2035\ttime=24911.89184975624\n",
      "i = 8100/65536\tverts=2040\ttime=25239.348574399948\n"
     ]
    }
   ],
   "source": [
    "temp = multiplyTrops(newFterms[0], newFterms[-1])\n",
    "ws, goodIndices = computeWs(temp, k=min(1000, temp.shape[0]-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
