{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# https://nextjournal.com/gkoehler/pytorch-mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import needed files and basic setup\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchvision\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "import data_gen2\n",
    "import tropical\n",
    "\n",
    "from ipywidgets import Output\n",
    "from IPython.display import display, Markdown, Latex, Math, clear_output\n",
    "\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "import math\n",
    "\n",
    "from cvxopt import solvers, matrix\n",
    "\n",
    "import time\n",
    "\n",
    "%matplotlib notebook\n",
    "#plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7f9baa91f7f0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "n_epochs = 100\n",
    "batch_size_train = 64\n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 100\n",
    "\n",
    "random_seed = 1\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load training and testing sets\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('files/', train=True, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_train, shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "  torchvision.datasets.MNIST('files/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ])),\n",
    "  batch_size=batch_size_test, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "examples = enumerate(test_loader)\n",
    "batch_idx, (example_data, example_targets) = next(examples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": [],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "network = Net()\n",
    "optimizer = optim.SGD(network.parameters(), lr=learning_rate,\n",
    "                      momentum=momentum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_losses = []\n",
    "train_acc = []\n",
    "train_counter = []\n",
    "test_losses = []\n",
    "test_acc = []\n",
    "test_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    network.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        optimizer.zero_grad()\n",
    "        output = network(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % log_interval == 0:\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct = pred.eq(target.data.view_as(pred)).sum()\n",
    "            \n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}\\tAccuracy: {:.6f}'.format(\n",
    "                  epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                  100. * batch_idx / len(train_loader), loss.item(), 100. * correct / 64))\n",
    "            \n",
    "            train_losses.append(loss.item())\n",
    "            train_acc.append(100. * correct / 64)\n",
    "            train_counter.append((batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "code_folding": [
     0
    ],
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test():\n",
    "    network.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = network(data)\n",
    "            test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "            pred = output.data.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_losses.append(test_loss)\n",
    "    test_acc.append(100. * correct / len(test_loader.dataset))\n",
    "    print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "          test_loss, correct, len(test_loader.dataset),\n",
    "          100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ben/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:12: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  if sys.path[0] == '':\n",
      "/home/ben/anaconda3/lib/python3.6/site-packages/torch/nn/functional.py:52: UserWarning: size_average and reduce args will be deprecated, please use reduction='sum' instead.\n",
      "  warnings.warn(warning.format(ret))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Avg. loss: 0.3481, Accuracy: 9031/10000 (90%)\n",
      "\n",
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 0.444591\tAccuracy: 82.000000\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 0.480439\tAccuracy: 84.000000\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.394207\tAccuracy: 89.000000\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.454035\tAccuracy: 82.000000\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.399961\tAccuracy: 90.000000\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.362256\tAccuracy: 92.000000\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.393363\tAccuracy: 92.000000\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.172308\tAccuracy: 95.000000\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.347486\tAccuracy: 89.000000\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.593781\tAccuracy: 82.000000\n",
      "\n",
      "Test set: Avg. loss: 0.2346, Accuracy: 9309/10000 (93%)\n",
      "\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.417614\tAccuracy: 84.000000\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.283681\tAccuracy: 90.000000\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.189972\tAccuracy: 96.000000\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.426772\tAccuracy: 85.000000\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.282014\tAccuracy: 90.000000\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.485318\tAccuracy: 85.000000\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.333970\tAccuracy: 89.000000\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.272816\tAccuracy: 93.000000\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.164835\tAccuracy: 93.000000\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.270796\tAccuracy: 93.000000\n",
      "\n",
      "Test set: Avg. loss: 0.1906, Accuracy: 9450/10000 (94%)\n",
      "\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.238545\tAccuracy: 95.000000\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.383758\tAccuracy: 87.000000\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.358916\tAccuracy: 92.000000\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.213141\tAccuracy: 93.000000\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.149228\tAccuracy: 96.000000\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.185626\tAccuracy: 95.000000\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.269254\tAccuracy: 93.000000\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.276946\tAccuracy: 93.000000\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.299081\tAccuracy: 93.000000\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.310797\tAccuracy: 93.000000\n",
      "\n",
      "Test set: Avg. loss: 0.1619, Accuracy: 9516/10000 (95%)\n",
      "\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.114999\tAccuracy: 98.000000\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.296235\tAccuracy: 92.000000\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.173364\tAccuracy: 95.000000\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.123686\tAccuracy: 98.000000\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.217833\tAccuracy: 92.000000\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.235680\tAccuracy: 90.000000\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.248752\tAccuracy: 93.000000\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.260488\tAccuracy: 92.000000\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.270437\tAccuracy: 89.000000\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.284767\tAccuracy: 90.000000\n",
      "\n",
      "Test set: Avg. loss: 0.1461, Accuracy: 9571/10000 (95%)\n",
      "\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.157421\tAccuracy: 95.000000\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.253740\tAccuracy: 93.000000\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.287615\tAccuracy: 89.000000\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.280577\tAccuracy: 90.000000\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.230990\tAccuracy: 92.000000\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.401900\tAccuracy: 90.000000\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.126167\tAccuracy: 96.000000\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.156936\tAccuracy: 92.000000\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.211682\tAccuracy: 92.000000\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.286466\tAccuracy: 90.000000\n",
      "\n",
      "Test set: Avg. loss: 0.1338, Accuracy: 9584/10000 (95%)\n",
      "\n",
      "Train Epoch: 6 [0/60000 (0%)]\tLoss: 0.186617\tAccuracy: 95.000000\n",
      "Train Epoch: 6 [6400/60000 (11%)]\tLoss: 0.147703\tAccuracy: 93.000000\n",
      "Train Epoch: 6 [12800/60000 (21%)]\tLoss: 0.108682\tAccuracy: 96.000000\n",
      "Train Epoch: 6 [19200/60000 (32%)]\tLoss: 0.159830\tAccuracy: 95.000000\n",
      "Train Epoch: 6 [25600/60000 (43%)]\tLoss: 0.139977\tAccuracy: 98.000000\n",
      "Train Epoch: 6 [32000/60000 (53%)]\tLoss: 0.119153\tAccuracy: 95.000000\n",
      "Train Epoch: 6 [38400/60000 (64%)]\tLoss: 0.091411\tAccuracy: 98.000000\n",
      "Train Epoch: 6 [44800/60000 (75%)]\tLoss: 0.136802\tAccuracy: 93.000000\n",
      "Train Epoch: 6 [51200/60000 (85%)]\tLoss: 0.271362\tAccuracy: 92.000000\n",
      "Train Epoch: 6 [57600/60000 (96%)]\tLoss: 0.127124\tAccuracy: 95.000000\n",
      "\n",
      "Test set: Avg. loss: 0.1239, Accuracy: 9626/10000 (96%)\n",
      "\n",
      "Train Epoch: 7 [0/60000 (0%)]\tLoss: 0.193859\tAccuracy: 90.000000\n",
      "Train Epoch: 7 [6400/60000 (11%)]\tLoss: 0.064173\tAccuracy: 96.000000\n",
      "Train Epoch: 7 [12800/60000 (21%)]\tLoss: 0.191466\tAccuracy: 93.000000\n",
      "Train Epoch: 7 [19200/60000 (32%)]\tLoss: 0.282754\tAccuracy: 93.000000\n",
      "Train Epoch: 7 [25600/60000 (43%)]\tLoss: 0.128696\tAccuracy: 96.000000\n",
      "Train Epoch: 7 [32000/60000 (53%)]\tLoss: 0.128067\tAccuracy: 96.000000\n",
      "Train Epoch: 7 [38400/60000 (64%)]\tLoss: 0.190774\tAccuracy: 95.000000\n",
      "Train Epoch: 7 [44800/60000 (75%)]\tLoss: 0.119274\tAccuracy: 96.000000\n",
      "Train Epoch: 7 [51200/60000 (85%)]\tLoss: 0.085308\tAccuracy: 98.000000\n",
      "Train Epoch: 7 [57600/60000 (96%)]\tLoss: 0.159539\tAccuracy: 93.000000\n",
      "\n",
      "Test set: Avg. loss: 0.1177, Accuracy: 9646/10000 (96%)\n",
      "\n",
      "Train Epoch: 8 [0/60000 (0%)]\tLoss: 0.203398\tAccuracy: 93.000000\n",
      "Train Epoch: 8 [6400/60000 (11%)]\tLoss: 0.257774\tAccuracy: 92.000000\n",
      "Train Epoch: 8 [12800/60000 (21%)]\tLoss: 0.249264\tAccuracy: 93.000000\n",
      "Train Epoch: 8 [19200/60000 (32%)]\tLoss: 0.092486\tAccuracy: 98.000000\n",
      "Train Epoch: 8 [25600/60000 (43%)]\tLoss: 0.142688\tAccuracy: 95.000000\n",
      "Train Epoch: 8 [32000/60000 (53%)]\tLoss: 0.192569\tAccuracy: 90.000000\n",
      "Train Epoch: 8 [38400/60000 (64%)]\tLoss: 0.102963\tAccuracy: 98.000000\n",
      "Train Epoch: 8 [44800/60000 (75%)]\tLoss: 0.121753\tAccuracy: 93.000000\n",
      "Train Epoch: 8 [51200/60000 (85%)]\tLoss: 0.152968\tAccuracy: 95.000000\n",
      "Train Epoch: 8 [57600/60000 (96%)]\tLoss: 0.268811\tAccuracy: 92.000000\n",
      "\n",
      "Test set: Avg. loss: 0.1116, Accuracy: 9673/10000 (96%)\n",
      "\n",
      "Train Epoch: 9 [0/60000 (0%)]\tLoss: 0.095629\tAccuracy: 96.000000\n",
      "Train Epoch: 9 [6400/60000 (11%)]\tLoss: 0.108863\tAccuracy: 93.000000\n",
      "Train Epoch: 9 [12800/60000 (21%)]\tLoss: 0.186712\tAccuracy: 95.000000\n",
      "Train Epoch: 9 [19200/60000 (32%)]\tLoss: 0.141413\tAccuracy: 96.000000\n",
      "Train Epoch: 9 [25600/60000 (43%)]\tLoss: 0.086687\tAccuracy: 96.000000\n",
      "Train Epoch: 9 [32000/60000 (53%)]\tLoss: 0.020106\tAccuracy: 100.000000\n",
      "Train Epoch: 9 [38400/60000 (64%)]\tLoss: 0.053355\tAccuracy: 98.000000\n",
      "Train Epoch: 9 [44800/60000 (75%)]\tLoss: 0.205937\tAccuracy: 93.000000\n",
      "Train Epoch: 9 [51200/60000 (85%)]\tLoss: 0.361782\tAccuracy: 89.000000\n",
      "Train Epoch: 9 [57600/60000 (96%)]\tLoss: 0.252873\tAccuracy: 92.000000\n",
      "\n",
      "Test set: Avg. loss: 0.1072, Accuracy: 9684/10000 (96%)\n",
      "\n",
      "Train Epoch: 10 [0/60000 (0%)]\tLoss: 0.286031\tAccuracy: 90.000000\n",
      "Train Epoch: 10 [6400/60000 (11%)]\tLoss: 0.107268\tAccuracy: 95.000000\n",
      "Train Epoch: 10 [12800/60000 (21%)]\tLoss: 0.271988\tAccuracy: 89.000000\n",
      "Train Epoch: 10 [19200/60000 (32%)]\tLoss: 0.082056\tAccuracy: 96.000000\n",
      "Train Epoch: 10 [25600/60000 (43%)]\tLoss: 0.407909\tAccuracy: 92.000000\n",
      "Train Epoch: 10 [32000/60000 (53%)]\tLoss: 0.084369\tAccuracy: 96.000000\n",
      "Train Epoch: 10 [38400/60000 (64%)]\tLoss: 0.097152\tAccuracy: 96.000000\n",
      "Train Epoch: 10 [44800/60000 (75%)]\tLoss: 0.209971\tAccuracy: 93.000000\n",
      "Train Epoch: 10 [51200/60000 (85%)]\tLoss: 0.185597\tAccuracy: 95.000000\n",
      "Train Epoch: 10 [57600/60000 (96%)]\tLoss: 0.239314\tAccuracy: 90.000000\n",
      "\n",
      "Test set: Avg. loss: 0.1029, Accuracy: 9688/10000 (96%)\n",
      "\n",
      "Train Epoch: 11 [0/60000 (0%)]\tLoss: 0.169168\tAccuracy: 93.000000\n",
      "Train Epoch: 11 [6400/60000 (11%)]\tLoss: 0.195006\tAccuracy: 95.000000\n",
      "Train Epoch: 11 [12800/60000 (21%)]\tLoss: 0.096381\tAccuracy: 98.000000\n",
      "Train Epoch: 11 [19200/60000 (32%)]\tLoss: 0.059566\tAccuracy: 98.000000\n",
      "Train Epoch: 11 [25600/60000 (43%)]\tLoss: 0.200624\tAccuracy: 95.000000\n",
      "Train Epoch: 11 [32000/60000 (53%)]\tLoss: 0.094191\tAccuracy: 96.000000\n",
      "Train Epoch: 11 [38400/60000 (64%)]\tLoss: 0.202913\tAccuracy: 93.000000\n",
      "Train Epoch: 11 [44800/60000 (75%)]\tLoss: 0.164019\tAccuracy: 95.000000\n",
      "Train Epoch: 11 [51200/60000 (85%)]\tLoss: 0.131666\tAccuracy: 96.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 11 [57600/60000 (96%)]\tLoss: 0.111513\tAccuracy: 96.000000\n",
      "\n",
      "Test set: Avg. loss: 0.1001, Accuracy: 9691/10000 (96%)\n",
      "\n",
      "Train Epoch: 12 [0/60000 (0%)]\tLoss: 0.084011\tAccuracy: 95.000000\n",
      "Train Epoch: 12 [6400/60000 (11%)]\tLoss: 0.107226\tAccuracy: 95.000000\n",
      "Train Epoch: 12 [12800/60000 (21%)]\tLoss: 0.084256\tAccuracy: 96.000000\n",
      "Train Epoch: 12 [19200/60000 (32%)]\tLoss: 0.100618\tAccuracy: 95.000000\n",
      "Train Epoch: 12 [25600/60000 (43%)]\tLoss: 0.131625\tAccuracy: 96.000000\n",
      "Train Epoch: 12 [32000/60000 (53%)]\tLoss: 0.063880\tAccuracy: 98.000000\n",
      "Train Epoch: 12 [38400/60000 (64%)]\tLoss: 0.123341\tAccuracy: 96.000000\n",
      "Train Epoch: 12 [44800/60000 (75%)]\tLoss: 0.146524\tAccuracy: 95.000000\n",
      "Train Epoch: 12 [51200/60000 (85%)]\tLoss: 0.166700\tAccuracy: 96.000000\n",
      "Train Epoch: 12 [57600/60000 (96%)]\tLoss: 0.153687\tAccuracy: 96.000000\n",
      "\n",
      "Test set: Avg. loss: 0.0966, Accuracy: 9697/10000 (96%)\n",
      "\n",
      "Train Epoch: 13 [0/60000 (0%)]\tLoss: 0.140710\tAccuracy: 93.000000\n",
      "Train Epoch: 13 [6400/60000 (11%)]\tLoss: 0.177338\tAccuracy: 93.000000\n",
      "Train Epoch: 13 [12800/60000 (21%)]\tLoss: 0.135116\tAccuracy: 96.000000\n",
      "Train Epoch: 13 [19200/60000 (32%)]\tLoss: 0.050830\tAccuracy: 100.000000\n",
      "Train Epoch: 13 [25600/60000 (43%)]\tLoss: 0.117369\tAccuracy: 96.000000\n",
      "Train Epoch: 13 [32000/60000 (53%)]\tLoss: 0.188468\tAccuracy: 93.000000\n",
      "Train Epoch: 13 [38400/60000 (64%)]\tLoss: 0.108868\tAccuracy: 95.000000\n",
      "Train Epoch: 13 [44800/60000 (75%)]\tLoss: 0.256463\tAccuracy: 92.000000\n",
      "Train Epoch: 13 [51200/60000 (85%)]\tLoss: 0.213440\tAccuracy: 95.000000\n",
      "Train Epoch: 13 [57600/60000 (96%)]\tLoss: 0.180516\tAccuracy: 96.000000\n",
      "\n",
      "Test set: Avg. loss: 0.0949, Accuracy: 9721/10000 (97%)\n",
      "\n",
      "Train Epoch: 14 [0/60000 (0%)]\tLoss: 0.104604\tAccuracy: 96.000000\n",
      "Train Epoch: 14 [6400/60000 (11%)]\tLoss: 0.139753\tAccuracy: 98.000000\n",
      "Train Epoch: 14 [12800/60000 (21%)]\tLoss: 0.129051\tAccuracy: 98.000000\n",
      "Train Epoch: 14 [19200/60000 (32%)]\tLoss: 0.192631\tAccuracy: 96.000000\n",
      "Train Epoch: 14 [25600/60000 (43%)]\tLoss: 0.100847\tAccuracy: 95.000000\n",
      "Train Epoch: 14 [32000/60000 (53%)]\tLoss: 0.381564\tAccuracy: 92.000000\n",
      "Train Epoch: 14 [38400/60000 (64%)]\tLoss: 0.129387\tAccuracy: 96.000000\n",
      "Train Epoch: 14 [44800/60000 (75%)]\tLoss: 0.129534\tAccuracy: 93.000000\n",
      "Train Epoch: 14 [51200/60000 (85%)]\tLoss: 0.124300\tAccuracy: 95.000000\n",
      "Train Epoch: 14 [57600/60000 (96%)]\tLoss: 0.107459\tAccuracy: 95.000000\n",
      "\n",
      "Test set: Avg. loss: 0.0918, Accuracy: 9720/10000 (97%)\n",
      "\n",
      "Train Epoch: 15 [0/60000 (0%)]\tLoss: 0.113642\tAccuracy: 96.000000\n",
      "Train Epoch: 15 [6400/60000 (11%)]\tLoss: 0.066881\tAccuracy: 98.000000\n",
      "Train Epoch: 15 [12800/60000 (21%)]\tLoss: 0.206011\tAccuracy: 95.000000\n",
      "Train Epoch: 15 [19200/60000 (32%)]\tLoss: 0.095428\tAccuracy: 96.000000\n",
      "Train Epoch: 15 [25600/60000 (43%)]\tLoss: 0.134368\tAccuracy: 98.000000\n",
      "Train Epoch: 15 [32000/60000 (53%)]\tLoss: 0.097304\tAccuracy: 93.000000\n",
      "Train Epoch: 15 [38400/60000 (64%)]\tLoss: 0.151054\tAccuracy: 92.000000\n",
      "Train Epoch: 15 [44800/60000 (75%)]\tLoss: 0.063029\tAccuracy: 98.000000\n",
      "Train Epoch: 15 [51200/60000 (85%)]\tLoss: 0.063767\tAccuracy: 98.000000\n",
      "Train Epoch: 15 [57600/60000 (96%)]\tLoss: 0.062472\tAccuracy: 96.000000\n",
      "\n",
      "Test set: Avg. loss: 0.0897, Accuracy: 9724/10000 (97%)\n",
      "\n",
      "Train Epoch: 16 [0/60000 (0%)]\tLoss: 0.103862\tAccuracy: 98.000000\n",
      "Train Epoch: 16 [6400/60000 (11%)]\tLoss: 0.185677\tAccuracy: 90.000000\n",
      "Train Epoch: 16 [12800/60000 (21%)]\tLoss: 0.307478\tAccuracy: 93.000000\n",
      "Train Epoch: 16 [19200/60000 (32%)]\tLoss: 0.219765\tAccuracy: 92.000000\n",
      "Train Epoch: 16 [25600/60000 (43%)]\tLoss: 0.120416\tAccuracy: 98.000000\n",
      "Train Epoch: 16 [32000/60000 (53%)]\tLoss: 0.100339\tAccuracy: 95.000000\n",
      "Train Epoch: 16 [38400/60000 (64%)]\tLoss: 0.186279\tAccuracy: 96.000000\n",
      "Train Epoch: 16 [44800/60000 (75%)]\tLoss: 0.163515\tAccuracy: 93.000000\n",
      "Train Epoch: 16 [51200/60000 (85%)]\tLoss: 0.063355\tAccuracy: 98.000000\n",
      "Train Epoch: 16 [57600/60000 (96%)]\tLoss: 0.145046\tAccuracy: 95.000000\n",
      "\n",
      "Test set: Avg. loss: 0.0891, Accuracy: 9730/10000 (97%)\n",
      "\n",
      "Train Epoch: 17 [0/60000 (0%)]\tLoss: 0.190734\tAccuracy: 92.000000\n",
      "Train Epoch: 17 [6400/60000 (11%)]\tLoss: 0.072914\tAccuracy: 96.000000\n",
      "Train Epoch: 17 [12800/60000 (21%)]\tLoss: 0.063992\tAccuracy: 98.000000\n",
      "Train Epoch: 17 [19200/60000 (32%)]\tLoss: 0.127413\tAccuracy: 95.000000\n",
      "Train Epoch: 17 [25600/60000 (43%)]\tLoss: 0.064007\tAccuracy: 98.000000\n",
      "Train Epoch: 17 [32000/60000 (53%)]\tLoss: 0.141445\tAccuracy: 98.000000\n",
      "Train Epoch: 17 [38400/60000 (64%)]\tLoss: 0.104272\tAccuracy: 93.000000\n",
      "Train Epoch: 17 [44800/60000 (75%)]\tLoss: 0.141125\tAccuracy: 93.000000\n",
      "Train Epoch: 17 [51200/60000 (85%)]\tLoss: 0.170643\tAccuracy: 93.000000\n",
      "Train Epoch: 17 [57600/60000 (96%)]\tLoss: 0.070832\tAccuracy: 96.000000\n",
      "\n",
      "Test set: Avg. loss: 0.0867, Accuracy: 9739/10000 (97%)\n",
      "\n",
      "Train Epoch: 18 [0/60000 (0%)]\tLoss: 0.107370\tAccuracy: 96.000000\n",
      "Train Epoch: 18 [6400/60000 (11%)]\tLoss: 0.087703\tAccuracy: 95.000000\n",
      "Train Epoch: 18 [12800/60000 (21%)]\tLoss: 0.144739\tAccuracy: 93.000000\n",
      "Train Epoch: 18 [19200/60000 (32%)]\tLoss: 0.120245\tAccuracy: 95.000000\n",
      "Train Epoch: 18 [25600/60000 (43%)]\tLoss: 0.276869\tAccuracy: 93.000000\n",
      "Train Epoch: 18 [32000/60000 (53%)]\tLoss: 0.110387\tAccuracy: 95.000000\n",
      "Train Epoch: 18 [38400/60000 (64%)]\tLoss: 0.272670\tAccuracy: 92.000000\n",
      "Train Epoch: 18 [44800/60000 (75%)]\tLoss: 0.071764\tAccuracy: 98.000000\n",
      "Train Epoch: 18 [51200/60000 (85%)]\tLoss: 0.239779\tAccuracy: 90.000000\n",
      "Train Epoch: 18 [57600/60000 (96%)]\tLoss: 0.107731\tAccuracy: 95.000000\n",
      "\n",
      "Test set: Avg. loss: 0.0862, Accuracy: 9737/10000 (97%)\n",
      "\n",
      "Train Epoch: 19 [0/60000 (0%)]\tLoss: 0.265870\tAccuracy: 93.000000\n",
      "Train Epoch: 19 [6400/60000 (11%)]\tLoss: 0.200128\tAccuracy: 92.000000\n",
      "Train Epoch: 19 [12800/60000 (21%)]\tLoss: 0.155942\tAccuracy: 96.000000\n",
      "Train Epoch: 19 [19200/60000 (32%)]\tLoss: 0.140021\tAccuracy: 98.000000\n",
      "Train Epoch: 19 [25600/60000 (43%)]\tLoss: 0.158866\tAccuracy: 90.000000\n",
      "Train Epoch: 19 [32000/60000 (53%)]\tLoss: 0.047027\tAccuracy: 98.000000\n",
      "Train Epoch: 19 [38400/60000 (64%)]\tLoss: 0.069359\tAccuracy: 98.000000\n",
      "Train Epoch: 19 [44800/60000 (75%)]\tLoss: 0.169329\tAccuracy: 90.000000\n",
      "Train Epoch: 19 [51200/60000 (85%)]\tLoss: 0.151437\tAccuracy: 98.000000\n",
      "Train Epoch: 19 [57600/60000 (96%)]\tLoss: 0.080048\tAccuracy: 96.000000\n",
      "\n",
      "Test set: Avg. loss: 0.0849, Accuracy: 9749/10000 (97%)\n",
      "\n",
      "Train Epoch: 20 [0/60000 (0%)]\tLoss: 0.130216\tAccuracy: 95.000000\n",
      "Train Epoch: 20 [6400/60000 (11%)]\tLoss: 0.062168\tAccuracy: 98.000000\n",
      "Train Epoch: 20 [12800/60000 (21%)]\tLoss: 0.050590\tAccuracy: 100.000000\n",
      "Train Epoch: 20 [19200/60000 (32%)]\tLoss: 0.042769\tAccuracy: 100.000000\n",
      "Train Epoch: 20 [25600/60000 (43%)]\tLoss: 0.128297\tAccuracy: 96.000000\n",
      "Train Epoch: 20 [32000/60000 (53%)]\tLoss: 0.074207\tAccuracy: 96.000000\n",
      "Train Epoch: 20 [38400/60000 (64%)]\tLoss: 0.051680\tAccuracy: 100.000000\n",
      "Train Epoch: 20 [44800/60000 (75%)]\tLoss: 0.064309\tAccuracy: 98.000000\n",
      "Train Epoch: 20 [51200/60000 (85%)]\tLoss: 0.133525\tAccuracy: 98.000000\n",
      "Train Epoch: 20 [57600/60000 (96%)]\tLoss: 0.032182\tAccuracy: 100.000000\n",
      "\n",
      "Test set: Avg. loss: 0.0827, Accuracy: 9757/10000 (97%)\n",
      "\n",
      "Train Epoch: 21 [0/60000 (0%)]\tLoss: 0.130933\tAccuracy: 96.000000\n",
      "Train Epoch: 21 [6400/60000 (11%)]\tLoss: 0.242047\tAccuracy: 93.000000\n",
      "Train Epoch: 21 [12800/60000 (21%)]\tLoss: 0.040330\tAccuracy: 98.000000\n",
      "Train Epoch: 21 [19200/60000 (32%)]\tLoss: 0.040895\tAccuracy: 96.000000\n",
      "Train Epoch: 21 [25600/60000 (43%)]\tLoss: 0.140827\tAccuracy: 96.000000\n",
      "Train Epoch: 21 [32000/60000 (53%)]\tLoss: 0.277135\tAccuracy: 93.000000\n",
      "Train Epoch: 21 [38400/60000 (64%)]\tLoss: 0.086192\tAccuracy: 95.000000\n",
      "Train Epoch: 21 [44800/60000 (75%)]\tLoss: 0.105219\tAccuracy: 96.000000\n",
      "Train Epoch: 21 [51200/60000 (85%)]\tLoss: 0.137474\tAccuracy: 96.000000\n",
      "Train Epoch: 21 [57600/60000 (96%)]\tLoss: 0.161211\tAccuracy: 96.000000\n",
      "\n",
      "Test set: Avg. loss: 0.0832, Accuracy: 9745/10000 (97%)\n",
      "\n",
      "Train Epoch: 22 [0/60000 (0%)]\tLoss: 0.160630\tAccuracy: 95.000000\n",
      "Train Epoch: 22 [6400/60000 (11%)]\tLoss: 0.049288\tAccuracy: 98.000000\n",
      "Train Epoch: 22 [12800/60000 (21%)]\tLoss: 0.084731\tAccuracy: 98.000000\n",
      "Train Epoch: 22 [19200/60000 (32%)]\tLoss: 0.220826\tAccuracy: 95.000000\n",
      "Train Epoch: 22 [25600/60000 (43%)]\tLoss: 0.027353\tAccuracy: 100.000000\n",
      "Train Epoch: 22 [32000/60000 (53%)]\tLoss: 0.052288\tAccuracy: 100.000000\n",
      "Train Epoch: 22 [38400/60000 (64%)]\tLoss: 0.119638\tAccuracy: 93.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 22 [44800/60000 (75%)]\tLoss: 0.190560\tAccuracy: 89.000000\n",
      "Train Epoch: 22 [51200/60000 (85%)]\tLoss: 0.042089\tAccuracy: 98.000000\n",
      "Train Epoch: 22 [57600/60000 (96%)]\tLoss: 0.030101\tAccuracy: 100.000000\n",
      "\n",
      "Test set: Avg. loss: 0.0826, Accuracy: 9752/10000 (97%)\n",
      "\n",
      "Train Epoch: 23 [0/60000 (0%)]\tLoss: 0.125240\tAccuracy: 95.000000\n",
      "Train Epoch: 23 [6400/60000 (11%)]\tLoss: 0.120387\tAccuracy: 96.000000\n",
      "Train Epoch: 23 [12800/60000 (21%)]\tLoss: 0.048984\tAccuracy: 98.000000\n",
      "Train Epoch: 23 [19200/60000 (32%)]\tLoss: 0.067666\tAccuracy: 98.000000\n",
      "Train Epoch: 23 [25600/60000 (43%)]\tLoss: 0.073256\tAccuracy: 98.000000\n",
      "Train Epoch: 23 [32000/60000 (53%)]\tLoss: 0.073005\tAccuracy: 98.000000\n",
      "Train Epoch: 23 [38400/60000 (64%)]\tLoss: 0.225846\tAccuracy: 93.000000\n",
      "Train Epoch: 23 [44800/60000 (75%)]\tLoss: 0.219127\tAccuracy: 93.000000\n",
      "Train Epoch: 23 [51200/60000 (85%)]\tLoss: 0.124392\tAccuracy: 93.000000\n",
      "Train Epoch: 23 [57600/60000 (96%)]\tLoss: 0.049597\tAccuracy: 98.000000\n",
      "\n",
      "Test set: Avg. loss: 0.0806, Accuracy: 9746/10000 (97%)\n",
      "\n",
      "Train Epoch: 24 [0/60000 (0%)]\tLoss: 0.066125\tAccuracy: 98.000000\n",
      "Train Epoch: 24 [6400/60000 (11%)]\tLoss: 0.156830\tAccuracy: 93.000000\n",
      "Train Epoch: 24 [12800/60000 (21%)]\tLoss: 0.082263\tAccuracy: 95.000000\n",
      "Train Epoch: 24 [19200/60000 (32%)]\tLoss: 0.107491\tAccuracy: 96.000000\n",
      "Train Epoch: 24 [25600/60000 (43%)]\tLoss: 0.055779\tAccuracy: 96.000000\n",
      "Train Epoch: 24 [32000/60000 (53%)]\tLoss: 0.016890\tAccuracy: 100.000000\n",
      "Train Epoch: 24 [38400/60000 (64%)]\tLoss: 0.079595\tAccuracy: 96.000000\n",
      "Train Epoch: 24 [44800/60000 (75%)]\tLoss: 0.159965\tAccuracy: 95.000000\n",
      "Train Epoch: 24 [51200/60000 (85%)]\tLoss: 0.098395\tAccuracy: 95.000000\n",
      "Train Epoch: 24 [57600/60000 (96%)]\tLoss: 0.179332\tAccuracy: 92.000000\n",
      "\n",
      "Test set: Avg. loss: 0.0805, Accuracy: 9758/10000 (97%)\n",
      "\n",
      "Train Epoch: 25 [0/60000 (0%)]\tLoss: 0.096976\tAccuracy: 96.000000\n",
      "Train Epoch: 25 [6400/60000 (11%)]\tLoss: 0.020791\tAccuracy: 100.000000\n",
      "Train Epoch: 25 [12800/60000 (21%)]\tLoss: 0.028188\tAccuracy: 100.000000\n",
      "Train Epoch: 25 [19200/60000 (32%)]\tLoss: 0.081235\tAccuracy: 98.000000\n",
      "Train Epoch: 25 [25600/60000 (43%)]\tLoss: 0.127423\tAccuracy: 96.000000\n",
      "Train Epoch: 25 [32000/60000 (53%)]\tLoss: 0.068465\tAccuracy: 98.000000\n",
      "Train Epoch: 25 [38400/60000 (64%)]\tLoss: 0.083237\tAccuracy: 96.000000\n",
      "Train Epoch: 25 [44800/60000 (75%)]\tLoss: 0.049266\tAccuracy: 100.000000\n",
      "Train Epoch: 25 [51200/60000 (85%)]\tLoss: 0.041984\tAccuracy: 100.000000\n",
      "Train Epoch: 25 [57600/60000 (96%)]\tLoss: 0.096893\tAccuracy: 96.000000\n",
      "\n",
      "Test set: Avg. loss: 0.0790, Accuracy: 9765/10000 (97%)\n",
      "\n",
      "Train Epoch: 26 [0/60000 (0%)]\tLoss: 0.163567\tAccuracy: 95.000000\n",
      "Train Epoch: 26 [6400/60000 (11%)]\tLoss: 0.144536\tAccuracy: 96.000000\n",
      "Train Epoch: 26 [12800/60000 (21%)]\tLoss: 0.050527\tAccuracy: 98.000000\n",
      "Train Epoch: 26 [19200/60000 (32%)]\tLoss: 0.056845\tAccuracy: 96.000000\n",
      "Train Epoch: 26 [25600/60000 (43%)]\tLoss: 0.094180\tAccuracy: 96.000000\n",
      "Train Epoch: 26 [32000/60000 (53%)]\tLoss: 0.071275\tAccuracy: 98.000000\n",
      "Train Epoch: 26 [38400/60000 (64%)]\tLoss: 0.179111\tAccuracy: 95.000000\n",
      "Train Epoch: 26 [44800/60000 (75%)]\tLoss: 0.041618\tAccuracy: 100.000000\n",
      "Train Epoch: 26 [51200/60000 (85%)]\tLoss: 0.075562\tAccuracy: 96.000000\n",
      "Train Epoch: 26 [57600/60000 (96%)]\tLoss: 0.039251\tAccuracy: 100.000000\n",
      "\n",
      "Test set: Avg. loss: 0.0794, Accuracy: 9754/10000 (97%)\n",
      "\n",
      "Train Epoch: 27 [0/60000 (0%)]\tLoss: 0.086447\tAccuracy: 96.000000\n",
      "Train Epoch: 27 [6400/60000 (11%)]\tLoss: 0.262856\tAccuracy: 95.000000\n",
      "Train Epoch: 27 [12800/60000 (21%)]\tLoss: 0.126064\tAccuracy: 98.000000\n",
      "Train Epoch: 27 [19200/60000 (32%)]\tLoss: 0.167768\tAccuracy: 96.000000\n",
      "Train Epoch: 27 [25600/60000 (43%)]\tLoss: 0.065837\tAccuracy: 96.000000\n",
      "Train Epoch: 27 [32000/60000 (53%)]\tLoss: 0.231689\tAccuracy: 93.000000\n",
      "Train Epoch: 27 [38400/60000 (64%)]\tLoss: 0.186895\tAccuracy: 93.000000\n",
      "Train Epoch: 27 [44800/60000 (75%)]\tLoss: 0.160670\tAccuracy: 96.000000\n",
      "Train Epoch: 27 [51200/60000 (85%)]\tLoss: 0.060306\tAccuracy: 98.000000\n",
      "Train Epoch: 27 [57600/60000 (96%)]\tLoss: 0.057217\tAccuracy: 98.000000\n",
      "\n",
      "Test set: Avg. loss: 0.0789, Accuracy: 9757/10000 (97%)\n",
      "\n",
      "Train Epoch: 28 [0/60000 (0%)]\tLoss: 0.081452\tAccuracy: 96.000000\n",
      "Train Epoch: 28 [6400/60000 (11%)]\tLoss: 0.097586\tAccuracy: 95.000000\n",
      "Train Epoch: 28 [12800/60000 (21%)]\tLoss: 0.044987\tAccuracy: 100.000000\n",
      "Train Epoch: 28 [19200/60000 (32%)]\tLoss: 0.088487\tAccuracy: 93.000000\n",
      "Train Epoch: 28 [25600/60000 (43%)]\tLoss: 0.071196\tAccuracy: 96.000000\n",
      "Train Epoch: 28 [32000/60000 (53%)]\tLoss: 0.064305\tAccuracy: 98.000000\n",
      "Train Epoch: 28 [38400/60000 (64%)]\tLoss: 0.065643\tAccuracy: 98.000000\n",
      "Train Epoch: 28 [44800/60000 (75%)]\tLoss: 0.032854\tAccuracy: 100.000000\n",
      "Train Epoch: 28 [51200/60000 (85%)]\tLoss: 0.079529\tAccuracy: 98.000000\n",
      "Train Epoch: 28 [57600/60000 (96%)]\tLoss: 0.068798\tAccuracy: 95.000000\n",
      "\n",
      "Test set: Avg. loss: 0.0776, Accuracy: 9763/10000 (97%)\n",
      "\n",
      "Train Epoch: 29 [0/60000 (0%)]\tLoss: 0.071217\tAccuracy: 98.000000\n",
      "Train Epoch: 29 [6400/60000 (11%)]\tLoss: 0.180334\tAccuracy: 95.000000\n",
      "Train Epoch: 29 [12800/60000 (21%)]\tLoss: 0.106585\tAccuracy: 95.000000\n",
      "Train Epoch: 29 [19200/60000 (32%)]\tLoss: 0.134633\tAccuracy: 95.000000\n",
      "Train Epoch: 29 [25600/60000 (43%)]\tLoss: 0.059646\tAccuracy: 96.000000\n",
      "Train Epoch: 29 [32000/60000 (53%)]\tLoss: 0.084816\tAccuracy: 96.000000\n",
      "Train Epoch: 29 [38400/60000 (64%)]\tLoss: 0.077495\tAccuracy: 96.000000\n",
      "Train Epoch: 29 [44800/60000 (75%)]\tLoss: 0.125966\tAccuracy: 95.000000\n",
      "Train Epoch: 29 [51200/60000 (85%)]\tLoss: 0.038806\tAccuracy: 100.000000\n",
      "Train Epoch: 29 [57600/60000 (96%)]\tLoss: 0.087000\tAccuracy: 98.000000\n",
      "\n",
      "Test set: Avg. loss: 0.0778, Accuracy: 9760/10000 (97%)\n",
      "\n",
      "Train Epoch: 30 [0/60000 (0%)]\tLoss: 0.083851\tAccuracy: 98.000000\n",
      "Train Epoch: 30 [6400/60000 (11%)]\tLoss: 0.197596\tAccuracy: 93.000000\n",
      "Train Epoch: 30 [12800/60000 (21%)]\tLoss: 0.303913\tAccuracy: 96.000000\n",
      "Train Epoch: 30 [19200/60000 (32%)]\tLoss: 0.069737\tAccuracy: 96.000000\n",
      "Train Epoch: 30 [25600/60000 (43%)]\tLoss: 0.112092\tAccuracy: 95.000000\n",
      "Train Epoch: 30 [32000/60000 (53%)]\tLoss: 0.098543\tAccuracy: 95.000000\n",
      "Train Epoch: 30 [38400/60000 (64%)]\tLoss: 0.159047\tAccuracy: 98.000000\n",
      "Train Epoch: 30 [44800/60000 (75%)]\tLoss: 0.068677\tAccuracy: 98.000000\n",
      "Train Epoch: 30 [51200/60000 (85%)]\tLoss: 0.094282\tAccuracy: 95.000000\n",
      "Train Epoch: 30 [57600/60000 (96%)]\tLoss: 0.080482\tAccuracy: 96.000000\n",
      "\n",
      "Test set: Avg. loss: 0.0783, Accuracy: 9767/10000 (97%)\n",
      "\n",
      "Train Epoch: 31 [0/60000 (0%)]\tLoss: 0.047967\tAccuracy: 100.000000\n",
      "Train Epoch: 31 [6400/60000 (11%)]\tLoss: 0.073936\tAccuracy: 98.000000\n",
      "Train Epoch: 31 [12800/60000 (21%)]\tLoss: 0.151686\tAccuracy: 96.000000\n",
      "Train Epoch: 31 [19200/60000 (32%)]\tLoss: 0.240809\tAccuracy: 95.000000\n",
      "Train Epoch: 31 [25600/60000 (43%)]\tLoss: 0.017307\tAccuracy: 100.000000\n",
      "Train Epoch: 31 [32000/60000 (53%)]\tLoss: 0.125759\tAccuracy: 95.000000\n",
      "Train Epoch: 31 [38400/60000 (64%)]\tLoss: 0.227293\tAccuracy: 93.000000\n",
      "Train Epoch: 31 [44800/60000 (75%)]\tLoss: 0.242828\tAccuracy: 92.000000\n",
      "Train Epoch: 31 [51200/60000 (85%)]\tLoss: 0.101440\tAccuracy: 96.000000\n",
      "Train Epoch: 31 [57600/60000 (96%)]\tLoss: 0.029086\tAccuracy: 100.000000\n",
      "\n",
      "Test set: Avg. loss: 0.0772, Accuracy: 9764/10000 (97%)\n",
      "\n",
      "Train Epoch: 32 [0/60000 (0%)]\tLoss: 0.058300\tAccuracy: 98.000000\n",
      "Train Epoch: 32 [6400/60000 (11%)]\tLoss: 0.125994\tAccuracy: 95.000000\n",
      "Train Epoch: 32 [12800/60000 (21%)]\tLoss: 0.105868\tAccuracy: 95.000000\n",
      "Train Epoch: 32 [19200/60000 (32%)]\tLoss: 0.133672\tAccuracy: 96.000000\n",
      "Train Epoch: 32 [25600/60000 (43%)]\tLoss: 0.106159\tAccuracy: 95.000000\n",
      "Train Epoch: 32 [32000/60000 (53%)]\tLoss: 0.183220\tAccuracy: 93.000000\n",
      "Train Epoch: 32 [38400/60000 (64%)]\tLoss: 0.077855\tAccuracy: 98.000000\n",
      "Train Epoch: 32 [44800/60000 (75%)]\tLoss: 0.051342\tAccuracy: 98.000000\n",
      "Train Epoch: 32 [51200/60000 (85%)]\tLoss: 0.076613\tAccuracy: 98.000000\n",
      "Train Epoch: 32 [57600/60000 (96%)]\tLoss: 0.191718\tAccuracy: 95.000000\n",
      "\n",
      "Test set: Avg. loss: 0.0761, Accuracy: 9757/10000 (97%)\n",
      "\n",
      "Train Epoch: 33 [0/60000 (0%)]\tLoss: 0.048390\tAccuracy: 98.000000\n",
      "Train Epoch: 33 [6400/60000 (11%)]\tLoss: 0.281721\tAccuracy: 93.000000\n",
      "Train Epoch: 33 [12800/60000 (21%)]\tLoss: 0.082709\tAccuracy: 96.000000\n",
      "Train Epoch: 33 [19200/60000 (32%)]\tLoss: 0.122851\tAccuracy: 95.000000\n",
      "Train Epoch: 33 [25600/60000 (43%)]\tLoss: 0.078394\tAccuracy: 96.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 33 [32000/60000 (53%)]\tLoss: 0.025237\tAccuracy: 100.000000\n",
      "Train Epoch: 33 [38400/60000 (64%)]\tLoss: 0.184723\tAccuracy: 93.000000\n",
      "Train Epoch: 33 [44800/60000 (75%)]\tLoss: 0.145407\tAccuracy: 96.000000\n",
      "Train Epoch: 33 [51200/60000 (85%)]\tLoss: 0.055430\tAccuracy: 98.000000\n",
      "Train Epoch: 33 [57600/60000 (96%)]\tLoss: 0.087557\tAccuracy: 96.000000\n",
      "\n",
      "Test set: Avg. loss: 0.0748, Accuracy: 9776/10000 (97%)\n",
      "\n",
      "Train Epoch: 34 [0/60000 (0%)]\tLoss: 0.097659\tAccuracy: 95.000000\n",
      "Train Epoch: 34 [6400/60000 (11%)]\tLoss: 0.047001\tAccuracy: 98.000000\n",
      "Train Epoch: 34 [12800/60000 (21%)]\tLoss: 0.050204\tAccuracy: 100.000000\n",
      "Train Epoch: 34 [19200/60000 (32%)]\tLoss: 0.124002\tAccuracy: 95.000000\n",
      "Train Epoch: 34 [25600/60000 (43%)]\tLoss: 0.101745\tAccuracy: 96.000000\n",
      "Train Epoch: 34 [32000/60000 (53%)]\tLoss: 0.120773\tAccuracy: 95.000000\n",
      "Train Epoch: 34 [38400/60000 (64%)]\tLoss: 0.074957\tAccuracy: 96.000000\n",
      "Train Epoch: 34 [44800/60000 (75%)]\tLoss: 0.040042\tAccuracy: 100.000000\n",
      "Train Epoch: 34 [51200/60000 (85%)]\tLoss: 0.190037\tAccuracy: 96.000000\n",
      "Train Epoch: 34 [57600/60000 (96%)]\tLoss: 0.128868\tAccuracy: 95.000000\n",
      "\n",
      "Test set: Avg. loss: 0.0747, Accuracy: 9778/10000 (97%)\n",
      "\n",
      "Train Epoch: 35 [0/60000 (0%)]\tLoss: 0.080288\tAccuracy: 95.000000\n",
      "Train Epoch: 35 [6400/60000 (11%)]\tLoss: 0.142233\tAccuracy: 96.000000\n",
      "Train Epoch: 35 [12800/60000 (21%)]\tLoss: 0.097590\tAccuracy: 95.000000\n",
      "Train Epoch: 35 [19200/60000 (32%)]\tLoss: 0.072840\tAccuracy: 96.000000\n",
      "Train Epoch: 35 [25600/60000 (43%)]\tLoss: 0.034248\tAccuracy: 100.000000\n",
      "Train Epoch: 35 [32000/60000 (53%)]\tLoss: 0.077478\tAccuracy: 96.000000\n",
      "Train Epoch: 35 [38400/60000 (64%)]\tLoss: 0.176902\tAccuracy: 93.000000\n",
      "Train Epoch: 35 [44800/60000 (75%)]\tLoss: 0.070008\tAccuracy: 95.000000\n",
      "Train Epoch: 35 [51200/60000 (85%)]\tLoss: 0.083780\tAccuracy: 96.000000\n",
      "Train Epoch: 35 [57600/60000 (96%)]\tLoss: 0.320187\tAccuracy: 87.000000\n",
      "\n",
      "Test set: Avg. loss: 0.0749, Accuracy: 9770/10000 (97%)\n",
      "\n",
      "Train Epoch: 36 [0/60000 (0%)]\tLoss: 0.106735\tAccuracy: 95.000000\n",
      "Train Epoch: 36 [6400/60000 (11%)]\tLoss: 0.070998\tAccuracy: 98.000000\n",
      "Train Epoch: 36 [12800/60000 (21%)]\tLoss: 0.261837\tAccuracy: 93.000000\n",
      "Train Epoch: 36 [19200/60000 (32%)]\tLoss: 0.134076\tAccuracy: 95.000000\n",
      "Train Epoch: 36 [25600/60000 (43%)]\tLoss: 0.131286\tAccuracy: 95.000000\n",
      "Train Epoch: 36 [32000/60000 (53%)]\tLoss: 0.128435\tAccuracy: 95.000000\n",
      "Train Epoch: 36 [38400/60000 (64%)]\tLoss: 0.138040\tAccuracy: 95.000000\n",
      "Train Epoch: 36 [44800/60000 (75%)]\tLoss: 0.097658\tAccuracy: 98.000000\n",
      "Train Epoch: 36 [51200/60000 (85%)]\tLoss: 0.087404\tAccuracy: 98.000000\n",
      "Train Epoch: 36 [57600/60000 (96%)]\tLoss: 0.017590\tAccuracy: 100.000000\n",
      "\n",
      "Test set: Avg. loss: 0.0751, Accuracy: 9776/10000 (97%)\n",
      "\n",
      "Train Epoch: 37 [0/60000 (0%)]\tLoss: 0.109893\tAccuracy: 95.000000\n",
      "Train Epoch: 37 [6400/60000 (11%)]\tLoss: 0.135411\tAccuracy: 98.000000\n",
      "Train Epoch: 37 [12800/60000 (21%)]\tLoss: 0.055647\tAccuracy: 98.000000\n",
      "Train Epoch: 37 [19200/60000 (32%)]\tLoss: 0.107390\tAccuracy: 93.000000\n",
      "Train Epoch: 37 [25600/60000 (43%)]\tLoss: 0.074578\tAccuracy: 96.000000\n",
      "Train Epoch: 37 [32000/60000 (53%)]\tLoss: 0.069666\tAccuracy: 96.000000\n",
      "Train Epoch: 37 [38400/60000 (64%)]\tLoss: 0.015410\tAccuracy: 100.000000\n",
      "Train Epoch: 37 [44800/60000 (75%)]\tLoss: 0.277155\tAccuracy: 93.000000\n",
      "Train Epoch: 37 [51200/60000 (85%)]\tLoss: 0.091062\tAccuracy: 98.000000\n",
      "Train Epoch: 37 [57600/60000 (96%)]\tLoss: 0.022021\tAccuracy: 100.000000\n",
      "\n",
      "Test set: Avg. loss: 0.0747, Accuracy: 9762/10000 (97%)\n",
      "\n",
      "Train Epoch: 38 [0/60000 (0%)]\tLoss: 0.100779\tAccuracy: 96.000000\n",
      "Train Epoch: 38 [6400/60000 (11%)]\tLoss: 0.046607\tAccuracy: 98.000000\n",
      "Train Epoch: 38 [12800/60000 (21%)]\tLoss: 0.073332\tAccuracy: 96.000000\n",
      "Train Epoch: 38 [19200/60000 (32%)]\tLoss: 0.077948\tAccuracy: 98.000000\n",
      "Train Epoch: 38 [25600/60000 (43%)]\tLoss: 0.042226\tAccuracy: 98.000000\n",
      "Train Epoch: 38 [32000/60000 (53%)]\tLoss: 0.188513\tAccuracy: 93.000000\n",
      "Train Epoch: 38 [38400/60000 (64%)]\tLoss: 0.039959\tAccuracy: 100.000000\n",
      "Train Epoch: 38 [44800/60000 (75%)]\tLoss: 0.088050\tAccuracy: 96.000000\n",
      "Train Epoch: 38 [51200/60000 (85%)]\tLoss: 0.105307\tAccuracy: 95.000000\n",
      "Train Epoch: 38 [57600/60000 (96%)]\tLoss: 0.044517\tAccuracy: 98.000000\n",
      "\n",
      "Test set: Avg. loss: 0.0753, Accuracy: 9772/10000 (97%)\n",
      "\n",
      "Train Epoch: 39 [0/60000 (0%)]\tLoss: 0.072627\tAccuracy: 96.000000\n",
      "Train Epoch: 39 [6400/60000 (11%)]\tLoss: 0.104873\tAccuracy: 95.000000\n",
      "Train Epoch: 39 [12800/60000 (21%)]\tLoss: 0.041389\tAccuracy: 100.000000\n",
      "Train Epoch: 39 [19200/60000 (32%)]\tLoss: 0.079560\tAccuracy: 93.000000\n",
      "Train Epoch: 39 [25600/60000 (43%)]\tLoss: 0.106402\tAccuracy: 96.000000\n",
      "Train Epoch: 39 [32000/60000 (53%)]\tLoss: 0.131666\tAccuracy: 95.000000\n",
      "Train Epoch: 39 [38400/60000 (64%)]\tLoss: 0.075230\tAccuracy: 96.000000\n",
      "Train Epoch: 39 [44800/60000 (75%)]\tLoss: 0.039251\tAccuracy: 96.000000\n",
      "Train Epoch: 39 [51200/60000 (85%)]\tLoss: 0.312762\tAccuracy: 95.000000\n",
      "Train Epoch: 39 [57600/60000 (96%)]\tLoss: 0.109752\tAccuracy: 96.000000\n",
      "\n",
      "Test set: Avg. loss: 0.0739, Accuracy: 9774/10000 (97%)\n",
      "\n",
      "Train Epoch: 40 [0/60000 (0%)]\tLoss: 0.073186\tAccuracy: 98.000000\n",
      "Train Epoch: 40 [6400/60000 (11%)]\tLoss: 0.011672\tAccuracy: 100.000000\n",
      "Train Epoch: 40 [12800/60000 (21%)]\tLoss: 0.053345\tAccuracy: 96.000000\n",
      "Train Epoch: 40 [19200/60000 (32%)]\tLoss: 0.115977\tAccuracy: 95.000000\n",
      "Train Epoch: 40 [25600/60000 (43%)]\tLoss: 0.078167\tAccuracy: 98.000000\n",
      "Train Epoch: 40 [32000/60000 (53%)]\tLoss: 0.048089\tAccuracy: 100.000000\n",
      "Train Epoch: 40 [38400/60000 (64%)]\tLoss: 0.077590\tAccuracy: 96.000000\n",
      "Train Epoch: 40 [44800/60000 (75%)]\tLoss: 0.057988\tAccuracy: 98.000000\n",
      "Train Epoch: 40 [51200/60000 (85%)]\tLoss: 0.119465\tAccuracy: 96.000000\n",
      "Train Epoch: 40 [57600/60000 (96%)]\tLoss: 0.054549\tAccuracy: 98.000000\n",
      "\n",
      "Test set: Avg. loss: 0.0725, Accuracy: 9782/10000 (97%)\n",
      "\n",
      "Train Epoch: 41 [0/60000 (0%)]\tLoss: 0.065254\tAccuracy: 96.000000\n",
      "Train Epoch: 41 [6400/60000 (11%)]\tLoss: 0.186397\tAccuracy: 92.000000\n",
      "Train Epoch: 41 [12800/60000 (21%)]\tLoss: 0.032263\tAccuracy: 98.000000\n",
      "Train Epoch: 41 [19200/60000 (32%)]\tLoss: 0.069627\tAccuracy: 96.000000\n",
      "Train Epoch: 41 [25600/60000 (43%)]\tLoss: 0.102214\tAccuracy: 96.000000\n",
      "Train Epoch: 41 [32000/60000 (53%)]\tLoss: 0.234882\tAccuracy: 92.000000\n",
      "Train Epoch: 41 [38400/60000 (64%)]\tLoss: 0.131728\tAccuracy: 95.000000\n",
      "Train Epoch: 41 [44800/60000 (75%)]\tLoss: 0.030604\tAccuracy: 98.000000\n",
      "Train Epoch: 41 [51200/60000 (85%)]\tLoss: 0.110352\tAccuracy: 96.000000\n",
      "Train Epoch: 41 [57600/60000 (96%)]\tLoss: 0.140205\tAccuracy: 96.000000\n",
      "\n",
      "Test set: Avg. loss: 0.0734, Accuracy: 9782/10000 (97%)\n",
      "\n",
      "Train Epoch: 42 [0/60000 (0%)]\tLoss: 0.205912\tAccuracy: 95.000000\n",
      "Train Epoch: 42 [6400/60000 (11%)]\tLoss: 0.229826\tAccuracy: 93.000000\n",
      "Train Epoch: 42 [12800/60000 (21%)]\tLoss: 0.102015\tAccuracy: 96.000000\n",
      "Train Epoch: 42 [19200/60000 (32%)]\tLoss: 0.115822\tAccuracy: 95.000000\n",
      "Train Epoch: 42 [25600/60000 (43%)]\tLoss: 0.064532\tAccuracy: 100.000000\n",
      "Train Epoch: 42 [32000/60000 (53%)]\tLoss: 0.073456\tAccuracy: 95.000000\n",
      "Train Epoch: 42 [38400/60000 (64%)]\tLoss: 0.124763\tAccuracy: 95.000000\n",
      "Train Epoch: 42 [44800/60000 (75%)]\tLoss: 0.055238\tAccuracy: 98.000000\n",
      "Train Epoch: 42 [51200/60000 (85%)]\tLoss: 0.050818\tAccuracy: 98.000000\n",
      "Train Epoch: 42 [57600/60000 (96%)]\tLoss: 0.039101\tAccuracy: 98.000000\n",
      "\n",
      "Test set: Avg. loss: 0.0743, Accuracy: 9772/10000 (97%)\n",
      "\n",
      "Train Epoch: 43 [0/60000 (0%)]\tLoss: 0.034218\tAccuracy: 98.000000\n",
      "Train Epoch: 43 [6400/60000 (11%)]\tLoss: 0.048105\tAccuracy: 98.000000\n",
      "Train Epoch: 43 [12800/60000 (21%)]\tLoss: 0.095898\tAccuracy: 95.000000\n",
      "Train Epoch: 43 [19200/60000 (32%)]\tLoss: 0.054811\tAccuracy: 96.000000\n",
      "Train Epoch: 43 [25600/60000 (43%)]\tLoss: 0.026755\tAccuracy: 100.000000\n",
      "Train Epoch: 43 [32000/60000 (53%)]\tLoss: 0.095904\tAccuracy: 95.000000\n",
      "Train Epoch: 43 [38400/60000 (64%)]\tLoss: 0.203792\tAccuracy: 95.000000\n",
      "Train Epoch: 43 [44800/60000 (75%)]\tLoss: 0.073911\tAccuracy: 96.000000\n",
      "Train Epoch: 43 [51200/60000 (85%)]\tLoss: 0.149164\tAccuracy: 96.000000\n",
      "Train Epoch: 43 [57600/60000 (96%)]\tLoss: 0.059564\tAccuracy: 98.000000\n",
      "\n",
      "Test set: Avg. loss: 0.0729, Accuracy: 9788/10000 (97%)\n",
      "\n",
      "Train Epoch: 44 [0/60000 (0%)]\tLoss: 0.038950\tAccuracy: 100.000000\n",
      "Train Epoch: 44 [6400/60000 (11%)]\tLoss: 0.055497\tAccuracy: 98.000000\n",
      "Train Epoch: 44 [12800/60000 (21%)]\tLoss: 0.118575\tAccuracy: 96.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 44 [19200/60000 (32%)]\tLoss: 0.078253\tAccuracy: 96.000000\n",
      "Train Epoch: 44 [25600/60000 (43%)]\tLoss: 0.060524\tAccuracy: 98.000000\n",
      "Train Epoch: 44 [32000/60000 (53%)]\tLoss: 0.018969\tAccuracy: 100.000000\n",
      "Train Epoch: 44 [38400/60000 (64%)]\tLoss: 0.072033\tAccuracy: 96.000000\n",
      "Train Epoch: 44 [44800/60000 (75%)]\tLoss: 0.081359\tAccuracy: 95.000000\n",
      "Train Epoch: 44 [51200/60000 (85%)]\tLoss: 0.060244\tAccuracy: 98.000000\n",
      "Train Epoch: 44 [57600/60000 (96%)]\tLoss: 0.030591\tAccuracy: 100.000000\n",
      "\n",
      "Test set: Avg. loss: 0.0726, Accuracy: 9782/10000 (97%)\n",
      "\n",
      "Train Epoch: 45 [0/60000 (0%)]\tLoss: 0.185998\tAccuracy: 95.000000\n",
      "Train Epoch: 45 [6400/60000 (11%)]\tLoss: 0.258415\tAccuracy: 93.000000\n",
      "Train Epoch: 45 [12800/60000 (21%)]\tLoss: 0.064044\tAccuracy: 98.000000\n",
      "Train Epoch: 45 [19200/60000 (32%)]\tLoss: 0.178417\tAccuracy: 95.000000\n",
      "Train Epoch: 45 [25600/60000 (43%)]\tLoss: 0.052912\tAccuracy: 96.000000\n",
      "Train Epoch: 45 [32000/60000 (53%)]\tLoss: 0.089804\tAccuracy: 93.000000\n",
      "Train Epoch: 45 [38400/60000 (64%)]\tLoss: 0.045826\tAccuracy: 100.000000\n",
      "Train Epoch: 45 [44800/60000 (75%)]\tLoss: 0.021495\tAccuracy: 100.000000\n",
      "Train Epoch: 45 [51200/60000 (85%)]\tLoss: 0.079230\tAccuracy: 96.000000\n",
      "Train Epoch: 45 [57600/60000 (96%)]\tLoss: 0.077365\tAccuracy: 96.000000\n",
      "\n",
      "Test set: Avg. loss: 0.0724, Accuracy: 9781/10000 (97%)\n",
      "\n",
      "Train Epoch: 46 [0/60000 (0%)]\tLoss: 0.079041\tAccuracy: 98.000000\n",
      "Train Epoch: 46 [6400/60000 (11%)]\tLoss: 0.110776\tAccuracy: 98.000000\n",
      "Train Epoch: 46 [12800/60000 (21%)]\tLoss: 0.018737\tAccuracy: 100.000000\n",
      "Train Epoch: 46 [19200/60000 (32%)]\tLoss: 0.043569\tAccuracy: 98.000000\n",
      "Train Epoch: 46 [25600/60000 (43%)]\tLoss: 0.097988\tAccuracy: 96.000000\n",
      "Train Epoch: 46 [32000/60000 (53%)]\tLoss: 0.041921\tAccuracy: 98.000000\n",
      "Train Epoch: 46 [38400/60000 (64%)]\tLoss: 0.183034\tAccuracy: 96.000000\n",
      "Train Epoch: 46 [44800/60000 (75%)]\tLoss: 0.139092\tAccuracy: 93.000000\n",
      "Train Epoch: 46 [51200/60000 (85%)]\tLoss: 0.031064\tAccuracy: 100.000000\n",
      "Train Epoch: 46 [57600/60000 (96%)]\tLoss: 0.013925\tAccuracy: 100.000000\n",
      "\n",
      "Test set: Avg. loss: 0.0742, Accuracy: 9776/10000 (97%)\n",
      "\n",
      "Train Epoch: 47 [0/60000 (0%)]\tLoss: 0.044064\tAccuracy: 96.000000\n",
      "Train Epoch: 47 [6400/60000 (11%)]\tLoss: 0.109361\tAccuracy: 95.000000\n",
      "Train Epoch: 47 [12800/60000 (21%)]\tLoss: 0.029536\tAccuracy: 100.000000\n",
      "Train Epoch: 47 [19200/60000 (32%)]\tLoss: 0.019688\tAccuracy: 100.000000\n",
      "Train Epoch: 47 [25600/60000 (43%)]\tLoss: 0.039101\tAccuracy: 98.000000\n",
      "Train Epoch: 47 [32000/60000 (53%)]\tLoss: 0.100092\tAccuracy: 96.000000\n",
      "Train Epoch: 47 [38400/60000 (64%)]\tLoss: 0.069665\tAccuracy: 96.000000\n",
      "Train Epoch: 47 [44800/60000 (75%)]\tLoss: 0.050760\tAccuracy: 98.000000\n",
      "Train Epoch: 47 [51200/60000 (85%)]\tLoss: 0.053687\tAccuracy: 96.000000\n",
      "Train Epoch: 47 [57600/60000 (96%)]\tLoss: 0.172369\tAccuracy: 95.000000\n",
      "\n",
      "Test set: Avg. loss: 0.0721, Accuracy: 9785/10000 (97%)\n",
      "\n",
      "Train Epoch: 48 [0/60000 (0%)]\tLoss: 0.150826\tAccuracy: 95.000000\n",
      "Train Epoch: 48 [6400/60000 (11%)]\tLoss: 0.175168\tAccuracy: 93.000000\n",
      "Train Epoch: 48 [12800/60000 (21%)]\tLoss: 0.149729\tAccuracy: 95.000000\n",
      "Train Epoch: 48 [19200/60000 (32%)]\tLoss: 0.101276\tAccuracy: 96.000000\n",
      "Train Epoch: 48 [25600/60000 (43%)]\tLoss: 0.060158\tAccuracy: 98.000000\n",
      "Train Epoch: 48 [32000/60000 (53%)]\tLoss: 0.021150\tAccuracy: 100.000000\n",
      "Train Epoch: 48 [38400/60000 (64%)]\tLoss: 0.049047\tAccuracy: 98.000000\n",
      "Train Epoch: 48 [44800/60000 (75%)]\tLoss: 0.225268\tAccuracy: 92.000000\n",
      "Train Epoch: 48 [51200/60000 (85%)]\tLoss: 0.095249\tAccuracy: 96.000000\n",
      "Train Epoch: 48 [57600/60000 (96%)]\tLoss: 0.037030\tAccuracy: 98.000000\n",
      "\n",
      "Test set: Avg. loss: 0.0721, Accuracy: 9783/10000 (97%)\n",
      "\n",
      "Train Epoch: 49 [0/60000 (0%)]\tLoss: 0.098862\tAccuracy: 96.000000\n",
      "Train Epoch: 49 [6400/60000 (11%)]\tLoss: 0.164735\tAccuracy: 93.000000\n",
      "Train Epoch: 49 [12800/60000 (21%)]\tLoss: 0.128747\tAccuracy: 95.000000\n",
      "Train Epoch: 49 [19200/60000 (32%)]\tLoss: 0.051683\tAccuracy: 100.000000\n",
      "Train Epoch: 49 [25600/60000 (43%)]\tLoss: 0.083156\tAccuracy: 95.000000\n",
      "Train Epoch: 49 [32000/60000 (53%)]\tLoss: 0.062642\tAccuracy: 98.000000\n",
      "Train Epoch: 49 [38400/60000 (64%)]\tLoss: 0.104909\tAccuracy: 96.000000\n",
      "Train Epoch: 49 [44800/60000 (75%)]\tLoss: 0.100542\tAccuracy: 96.000000\n",
      "Train Epoch: 49 [51200/60000 (85%)]\tLoss: 0.084618\tAccuracy: 98.000000\n",
      "Train Epoch: 49 [57600/60000 (96%)]\tLoss: 0.066686\tAccuracy: 98.000000\n",
      "\n",
      "Test set: Avg. loss: 0.0736, Accuracy: 9777/10000 (97%)\n",
      "\n",
      "Train Epoch: 50 [0/60000 (0%)]\tLoss: 0.054887\tAccuracy: 98.000000\n",
      "Train Epoch: 50 [6400/60000 (11%)]\tLoss: 0.067152\tAccuracy: 98.000000\n",
      "Train Epoch: 50 [12800/60000 (21%)]\tLoss: 0.148208\tAccuracy: 92.000000\n",
      "Train Epoch: 50 [19200/60000 (32%)]\tLoss: 0.047503\tAccuracy: 98.000000\n",
      "Train Epoch: 50 [25600/60000 (43%)]\tLoss: 0.095975\tAccuracy: 95.000000\n",
      "Train Epoch: 50 [32000/60000 (53%)]\tLoss: 0.054709\tAccuracy: 98.000000\n",
      "Train Epoch: 50 [38400/60000 (64%)]\tLoss: 0.085379\tAccuracy: 96.000000\n",
      "Train Epoch: 50 [44800/60000 (75%)]\tLoss: 0.007122\tAccuracy: 100.000000\n",
      "Train Epoch: 50 [51200/60000 (85%)]\tLoss: 0.044766\tAccuracy: 98.000000\n",
      "Train Epoch: 50 [57600/60000 (96%)]\tLoss: 0.133684\tAccuracy: 98.000000\n",
      "\n",
      "Test set: Avg. loss: 0.0719, Accuracy: 9785/10000 (97%)\n",
      "\n",
      "Train Epoch: 51 [0/60000 (0%)]\tLoss: 0.074662\tAccuracy: 96.000000\n",
      "Train Epoch: 51 [6400/60000 (11%)]\tLoss: 0.113991\tAccuracy: 93.000000\n",
      "Train Epoch: 51 [12800/60000 (21%)]\tLoss: 0.120868\tAccuracy: 96.000000\n",
      "Train Epoch: 51 [19200/60000 (32%)]\tLoss: 0.053082\tAccuracy: 98.000000\n",
      "Train Epoch: 51 [25600/60000 (43%)]\tLoss: 0.099585\tAccuracy: 96.000000\n",
      "Train Epoch: 51 [32000/60000 (53%)]\tLoss: 0.030044\tAccuracy: 100.000000\n",
      "Train Epoch: 51 [38400/60000 (64%)]\tLoss: 0.094746\tAccuracy: 96.000000\n",
      "Train Epoch: 51 [44800/60000 (75%)]\tLoss: 0.041129\tAccuracy: 98.000000\n",
      "Train Epoch: 51 [51200/60000 (85%)]\tLoss: 0.085588\tAccuracy: 98.000000\n",
      "Train Epoch: 51 [57600/60000 (96%)]\tLoss: 0.114933\tAccuracy: 98.000000\n",
      "\n",
      "Test set: Avg. loss: 0.0733, Accuracy: 9781/10000 (97%)\n",
      "\n",
      "Train Epoch: 52 [0/60000 (0%)]\tLoss: 0.113037\tAccuracy: 96.000000\n",
      "Train Epoch: 52 [6400/60000 (11%)]\tLoss: 0.076487\tAccuracy: 98.000000\n",
      "Train Epoch: 52 [12800/60000 (21%)]\tLoss: 0.139254\tAccuracy: 93.000000\n",
      "Train Epoch: 52 [19200/60000 (32%)]\tLoss: 0.099183\tAccuracy: 98.000000\n",
      "Train Epoch: 52 [25600/60000 (43%)]\tLoss: 0.106241\tAccuracy: 96.000000\n",
      "Train Epoch: 52 [32000/60000 (53%)]\tLoss: 0.080361\tAccuracy: 96.000000\n",
      "Train Epoch: 52 [38400/60000 (64%)]\tLoss: 0.114792\tAccuracy: 95.000000\n",
      "Train Epoch: 52 [44800/60000 (75%)]\tLoss: 0.019464\tAccuracy: 100.000000\n",
      "Train Epoch: 52 [51200/60000 (85%)]\tLoss: 0.042676\tAccuracy: 98.000000\n",
      "Train Epoch: 52 [57600/60000 (96%)]\tLoss: 0.157377\tAccuracy: 95.000000\n",
      "\n",
      "Test set: Avg. loss: 0.0704, Accuracy: 9792/10000 (97%)\n",
      "\n",
      "Train Epoch: 53 [0/60000 (0%)]\tLoss: 0.228849\tAccuracy: 95.000000\n",
      "Train Epoch: 53 [6400/60000 (11%)]\tLoss: 0.051632\tAccuracy: 98.000000\n",
      "Train Epoch: 53 [12800/60000 (21%)]\tLoss: 0.050518\tAccuracy: 98.000000\n",
      "Train Epoch: 53 [19200/60000 (32%)]\tLoss: 0.212664\tAccuracy: 93.000000\n",
      "Train Epoch: 53 [25600/60000 (43%)]\tLoss: 0.062102\tAccuracy: 96.000000\n",
      "Train Epoch: 53 [32000/60000 (53%)]\tLoss: 0.066921\tAccuracy: 100.000000\n",
      "Train Epoch: 53 [38400/60000 (64%)]\tLoss: 0.066545\tAccuracy: 98.000000\n",
      "Train Epoch: 53 [44800/60000 (75%)]\tLoss: 0.055428\tAccuracy: 98.000000\n",
      "Train Epoch: 53 [51200/60000 (85%)]\tLoss: 0.039088\tAccuracy: 100.000000\n",
      "Train Epoch: 53 [57600/60000 (96%)]\tLoss: 0.091672\tAccuracy: 98.000000\n",
      "\n",
      "Test set: Avg. loss: 0.0730, Accuracy: 9782/10000 (97%)\n",
      "\n",
      "Train Epoch: 54 [0/60000 (0%)]\tLoss: 0.083387\tAccuracy: 98.000000\n",
      "Train Epoch: 54 [6400/60000 (11%)]\tLoss: 0.053749\tAccuracy: 98.000000\n",
      "Train Epoch: 54 [12800/60000 (21%)]\tLoss: 0.053022\tAccuracy: 98.000000\n",
      "Train Epoch: 54 [19200/60000 (32%)]\tLoss: 0.014517\tAccuracy: 100.000000\n",
      "Train Epoch: 54 [25600/60000 (43%)]\tLoss: 0.034736\tAccuracy: 98.000000\n",
      "Train Epoch: 54 [32000/60000 (53%)]\tLoss: 0.035456\tAccuracy: 98.000000\n",
      "Train Epoch: 54 [38400/60000 (64%)]\tLoss: 0.048892\tAccuracy: 96.000000\n",
      "Train Epoch: 54 [44800/60000 (75%)]\tLoss: 0.095959\tAccuracy: 96.000000\n",
      "Train Epoch: 54 [51200/60000 (85%)]\tLoss: 0.063213\tAccuracy: 98.000000\n",
      "Train Epoch: 54 [57600/60000 (96%)]\tLoss: 0.085305\tAccuracy: 98.000000\n",
      "\n",
      "Test set: Avg. loss: 0.0711, Accuracy: 9789/10000 (97%)\n",
      "\n",
      "Train Epoch: 55 [0/60000 (0%)]\tLoss: 0.073126\tAccuracy: 95.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 55 [6400/60000 (11%)]\tLoss: 0.034145\tAccuracy: 100.000000\n",
      "Train Epoch: 55 [12800/60000 (21%)]\tLoss: 0.038974\tAccuracy: 98.000000\n",
      "Train Epoch: 55 [19200/60000 (32%)]\tLoss: 0.026253\tAccuracy: 100.000000\n",
      "Train Epoch: 55 [25600/60000 (43%)]\tLoss: 0.045302\tAccuracy: 98.000000\n",
      "Train Epoch: 55 [32000/60000 (53%)]\tLoss: 0.054934\tAccuracy: 98.000000\n",
      "Train Epoch: 55 [38400/60000 (64%)]\tLoss: 0.055202\tAccuracy: 98.000000\n",
      "Train Epoch: 55 [44800/60000 (75%)]\tLoss: 0.030292\tAccuracy: 100.000000\n",
      "Train Epoch: 55 [51200/60000 (85%)]\tLoss: 0.169946\tAccuracy: 95.000000\n",
      "Train Epoch: 55 [57600/60000 (96%)]\tLoss: 0.047554\tAccuracy: 98.000000\n",
      "\n",
      "Test set: Avg. loss: 0.0718, Accuracy: 9787/10000 (97%)\n",
      "\n",
      "Train Epoch: 56 [0/60000 (0%)]\tLoss: 0.032121\tAccuracy: 100.000000\n",
      "Train Epoch: 56 [6400/60000 (11%)]\tLoss: 0.073012\tAccuracy: 96.000000\n",
      "Train Epoch: 56 [12800/60000 (21%)]\tLoss: 0.102379\tAccuracy: 96.000000\n",
      "Train Epoch: 56 [19200/60000 (32%)]\tLoss: 0.109979\tAccuracy: 98.000000\n",
      "Train Epoch: 56 [25600/60000 (43%)]\tLoss: 0.116350\tAccuracy: 96.000000\n",
      "Train Epoch: 56 [32000/60000 (53%)]\tLoss: 0.042067\tAccuracy: 98.000000\n",
      "Train Epoch: 56 [38400/60000 (64%)]\tLoss: 0.034265\tAccuracy: 100.000000\n",
      "Train Epoch: 56 [44800/60000 (75%)]\tLoss: 0.018291\tAccuracy: 100.000000\n",
      "Train Epoch: 56 [51200/60000 (85%)]\tLoss: 0.107620\tAccuracy: 95.000000\n",
      "Train Epoch: 56 [57600/60000 (96%)]\tLoss: 0.134525\tAccuracy: 92.000000\n",
      "\n",
      "Test set: Avg. loss: 0.0722, Accuracy: 9792/10000 (97%)\n",
      "\n",
      "Train Epoch: 57 [0/60000 (0%)]\tLoss: 0.041636\tAccuracy: 98.000000\n",
      "Train Epoch: 57 [6400/60000 (11%)]\tLoss: 0.113079\tAccuracy: 96.000000\n",
      "Train Epoch: 57 [12800/60000 (21%)]\tLoss: 0.060963\tAccuracy: 96.000000\n",
      "Train Epoch: 57 [19200/60000 (32%)]\tLoss: 0.127639\tAccuracy: 96.000000\n",
      "Train Epoch: 57 [25600/60000 (43%)]\tLoss: 0.090234\tAccuracy: 95.000000\n",
      "Train Epoch: 57 [32000/60000 (53%)]\tLoss: 0.035177\tAccuracy: 100.000000\n",
      "Train Epoch: 57 [38400/60000 (64%)]\tLoss: 0.085812\tAccuracy: 93.000000\n",
      "Train Epoch: 57 [44800/60000 (75%)]\tLoss: 0.039983\tAccuracy: 100.000000\n",
      "Train Epoch: 57 [51200/60000 (85%)]\tLoss: 0.008850\tAccuracy: 100.000000\n",
      "Train Epoch: 57 [57600/60000 (96%)]\tLoss: 0.043795\tAccuracy: 98.000000\n",
      "\n",
      "Test set: Avg. loss: 0.0724, Accuracy: 9785/10000 (97%)\n",
      "\n",
      "Train Epoch: 58 [0/60000 (0%)]\tLoss: 0.018160\tAccuracy: 100.000000\n",
      "Train Epoch: 58 [6400/60000 (11%)]\tLoss: 0.148328\tAccuracy: 96.000000\n",
      "Train Epoch: 58 [12800/60000 (21%)]\tLoss: 0.060367\tAccuracy: 98.000000\n",
      "Train Epoch: 58 [19200/60000 (32%)]\tLoss: 0.125339\tAccuracy: 96.000000\n",
      "Train Epoch: 58 [25600/60000 (43%)]\tLoss: 0.027640\tAccuracy: 100.000000\n",
      "Train Epoch: 58 [32000/60000 (53%)]\tLoss: 0.057872\tAccuracy: 98.000000\n",
      "Train Epoch: 58 [38400/60000 (64%)]\tLoss: 0.051433\tAccuracy: 96.000000\n",
      "Train Epoch: 58 [44800/60000 (75%)]\tLoss: 0.032527\tAccuracy: 100.000000\n",
      "Train Epoch: 58 [51200/60000 (85%)]\tLoss: 0.086448\tAccuracy: 96.000000\n",
      "Train Epoch: 58 [57600/60000 (96%)]\tLoss: 0.084858\tAccuracy: 98.000000\n",
      "\n",
      "Test set: Avg. loss: 0.0710, Accuracy: 9783/10000 (97%)\n",
      "\n",
      "Train Epoch: 59 [0/60000 (0%)]\tLoss: 0.037219\tAccuracy: 98.000000\n",
      "Train Epoch: 59 [6400/60000 (11%)]\tLoss: 0.032527\tAccuracy: 100.000000\n",
      "Train Epoch: 59 [12800/60000 (21%)]\tLoss: 0.046250\tAccuracy: 98.000000\n",
      "Train Epoch: 59 [19200/60000 (32%)]\tLoss: 0.046582\tAccuracy: 98.000000\n",
      "Train Epoch: 59 [25600/60000 (43%)]\tLoss: 0.078376\tAccuracy: 98.000000\n",
      "Train Epoch: 59 [32000/60000 (53%)]\tLoss: 0.066091\tAccuracy: 96.000000\n",
      "Train Epoch: 59 [38400/60000 (64%)]\tLoss: 0.077572\tAccuracy: 96.000000\n",
      "Train Epoch: 59 [44800/60000 (75%)]\tLoss: 0.115352\tAccuracy: 96.000000\n",
      "Train Epoch: 59 [51200/60000 (85%)]\tLoss: 0.218754\tAccuracy: 95.000000\n",
      "Train Epoch: 59 [57600/60000 (96%)]\tLoss: 0.105350\tAccuracy: 96.000000\n",
      "\n",
      "Test set: Avg. loss: 0.0721, Accuracy: 9780/10000 (97%)\n",
      "\n",
      "Train Epoch: 60 [0/60000 (0%)]\tLoss: 0.095459\tAccuracy: 95.000000\n",
      "Train Epoch: 60 [6400/60000 (11%)]\tLoss: 0.185821\tAccuracy: 96.000000\n",
      "Train Epoch: 60 [12800/60000 (21%)]\tLoss: 0.038499\tAccuracy: 98.000000\n",
      "Train Epoch: 60 [19200/60000 (32%)]\tLoss: 0.088789\tAccuracy: 98.000000\n",
      "Train Epoch: 60 [25600/60000 (43%)]\tLoss: 0.082273\tAccuracy: 96.000000\n",
      "Train Epoch: 60 [32000/60000 (53%)]\tLoss: 0.053300\tAccuracy: 98.000000\n",
      "Train Epoch: 60 [38400/60000 (64%)]\tLoss: 0.023377\tAccuracy: 100.000000\n",
      "Train Epoch: 60 [44800/60000 (75%)]\tLoss: 0.103672\tAccuracy: 98.000000\n",
      "Train Epoch: 60 [51200/60000 (85%)]\tLoss: 0.061798\tAccuracy: 98.000000\n",
      "Train Epoch: 60 [57600/60000 (96%)]\tLoss: 0.056165\tAccuracy: 98.000000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-14-6d59ea1b2144>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-13-bf51d497d322>\u001b[0m in \u001b[0;36mtest\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mcorrect\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0mtest_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize_average\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ben/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ben/anaconda3/lib/python3.6/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_workers\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# same-process loading\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m             \u001b[0mindices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msample_iter\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mindices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    316\u001b[0m                 \u001b[0mbatch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpin_memory_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ben/anaconda3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/datasets/mnist.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 77\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ben/anaconda3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ben/anaconda3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    141\u001b[0m             \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNormalized\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m         \"\"\"\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnormalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ben/anaconda3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mnormalize\u001b[0;34m(tensor, mean, std)\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNormalized\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m     \"\"\"\n\u001b[0;32m--> 164\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_is_tensor_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'tensor is not a torch image.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m     \u001b[0;31m# TODO: make efficient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ben/anaconda3/lib/python3.6/site-packages/torchvision-0.2.1-py3.6.egg/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36m_is_tensor_image\u001b[0;34m(img)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_is_tensor_image\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndimension\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "test()\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# fig = plt.figure()\n",
    "# plt.plot(train_counter, train_acc, color='blue')\n",
    "# plt.plot(test_counter, test_acc, 'o', color='red')\n",
    "# plt.legend(['Train Loss', 'Test Loss'], loc='upper right')\n",
    "# plt.xlabel('number of training examples seen')\n",
    "# plt.ylabel('negative log likelihood loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params = []\n",
    "for param in network.parameters():\n",
    "    params.append(param.detach().numpy())\n",
    "\n",
    "A1 = params[0]\n",
    "b1 = params[1]\n",
    "A2 = params[2][0,:].reshape((1, -1))\n",
    "b2 = params[3][:1]\n",
    "\n",
    "#Fterms, Gterms = tropical.getTropCoeffs(A1, b1, A2, b2, doTime=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Ftermsfull = []\n",
    "Gtermsfull = []\n",
    "for i in range(0, np.size(A1, axis = 0), 10):\n",
    "    Fterms, Gterms = tropical.getTropCoeffs(A1[i:i+10, :], b1[i:i+10], A2[:, i:i+10], b2)\n",
    "    Ftermsfull.append(Fterms)\n",
    "    Gtermsfull.append(Gterms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 32\n",
      "8 128\n",
      "32 32\n",
      "128 8\n",
      "64 16\n",
      "32 32\n",
      "16 64\n",
      "16 64\n",
      "16 64\n",
      "32 32\n",
      "4 256\n",
      "8 128\n",
      "16 16\n",
      "57.0 71.0\n"
     ]
    }
   ],
   "source": [
    "prodF = 1\n",
    "prodG = 1\n",
    "for i in range(len(Ftermsfull)):\n",
    "    print(len(Ftermsfull[i]), len(Gtermsfull[i]))\n",
    "    prodF *= len(Ftermsfull[i])\n",
    "    prodG *= len(Gtermsfull[i])\n",
    "    \n",
    "print(math.log(prodF, 2), math.log(prodG, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def multiplyTrops(trop1, trop2):\n",
    "    temp = trop1 + trop2[0, :]\n",
    "    for i in range(1, trop2.shape[0]):\n",
    "        temp = np.vstack((temp, trop1 + trop2[i, :]))\n",
    "    return temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "solvers.options['show_progress'] = False\n",
    "def computeW(i, k, lam, gam, nbrs, temp):\n",
    "    _, indices = nbrs.kneighbors(temp[i:i+1, :])\n",
    "    indices = indices[0,1:]\n",
    "    neighbors = temp[indices, :]\n",
    "\n",
    "    # Set up quadratic programming problem\n",
    "    Qtild = np.dot(temp[indices, :], temp[indices, :].T)\n",
    "    Etild = np.eye(k)\n",
    "    E = gam*np.bmat([[Etild, -Etild], [-Etild, Etild]])\n",
    "\n",
    "    A = np.ones((2*k, 1))\n",
    "    A[k:, :] = -1\n",
    "\n",
    "    G = -np.eye(2*k)\n",
    "    h = np.zeros((2*k, 1))\n",
    "\n",
    "    b = np.array([1.0]).reshape(1,1)\n",
    "    Q = np.bmat([[Qtild, -Qtild], [-Qtild, Qtild]]) + E\n",
    "    \n",
    "    c = np.dot(temp[indices, :], temp[i, :])\n",
    "    c = c.reshape(-1, 1)\n",
    "    c = np.bmat([[-c], [c]]) + lam\n",
    "    \n",
    "    # Solve quadratic programming problem\n",
    "    out = solvers.qp(matrix(Q), matrix(c), matrix(G), matrix(h), matrix(A.T), matrix(b))\n",
    "    \n",
    "    # If there are negative weight values, it's near the convex hull\n",
    "    w = np.array(out['x'])[:k] - np.array(out['x'])[k:]\n",
    "    return w\n",
    "\n",
    "def computeWs(points, k=1000, lam=1e-3, gam=1e-6):\n",
    "    # Rescale points to roughly 0 to 1\n",
    "    shift = np.amin(points)\n",
    "    points = points - shift\n",
    "    scale = np.amax(points)\n",
    "    points = points/scale\n",
    "    nbrs = NearestNeighbors(n_neighbors=k+1).fit(points)\n",
    "    goodIndices = []\n",
    "    ws = np.zeros((points.shape[0], k))\n",
    "\n",
    "    start = time.time()\n",
    "    end = points.shape[0]\n",
    "    for i in range(end):\n",
    "        w = computeW(i, k, lam, gam, nbrs, points)\n",
    "        ws[i, :] = w.T\n",
    "        if np.sum(w < 0) > 0:\n",
    "            goodIndices.append(i)\n",
    "        if (i+1) % 100 == 0 or i+1 == end or i == 0:\n",
    "            print('i = {}/{}\\tverts={}\\ttime={}'.format(i+1, end, len(goodIndices), time.time()-start))\n",
    "            \n",
    "    return ws, goodIndices\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "def computeWsParallel(points, k=1000, lam=1e-3, gam=1e-6):\n",
    "    shift = np.amin(points)\n",
    "    points = points - shift\n",
    "    scale = np.amax(points)\n",
    "    points = points/scale\n",
    "    nbrs = NearestNeighbors(n_neighbors=k+1).fit(points)\n",
    "    goodIndices = []\n",
    "    ws = np.zeros((points.shape[0], k))\n",
    "\n",
    "    start = time.time()\n",
    "    end = points.shape[0]\n",
    "    for i in range(0, end, 100):\n",
    "        wsT = Parallel(n_jobs=4)(delayed(computeW)(i, k, lam, gam, nbrs, points) for i in range(i, max(i+100, end)))\n",
    "        for j in range(len(wsT)):\n",
    "            ws[i, :] = wsT[j].T\n",
    "            if np.sum(wsT[j] < 0) > 0:\n",
    "                goodIndices.append(i + j)\n",
    "            print('i = {}/{}\\tverts={}\\ttime={}'.format(i+j+1, end, len(goodIndices), time.time()-start))\n",
    "            \n",
    "    return ws, goodIndices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from joblib import Parallel, delayed\n",
    "# start = time.time()\n",
    "# ws = Parallel(n_jobs=4)(delayed(computeW)(i) for i in range(16))\n",
    "# print(start - time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 1/256\tverts=1\ttime=0.1315152645111084\n",
      "i = 100/256\tverts=100\ttime=10.98108959197998\n",
      "i = 200/256\tverts=200\ttime=21.91749143600464\n",
      "i = 256/256\tverts=256\ttime=27.982080936431885\n",
      "i = 1/4096\tverts=1\ttime=1.5399019718170166\n",
      "i = 100/4096\tverts=100\ttime=155.4342246055603\n",
      "i = 200/4096\tverts=200\ttime=319.23856377601624\n",
      "i = 300/4096\tverts=300\ttime=481.1208655834198\n",
      "i = 400/4096\tverts=400\ttime=637.0060093402863\n",
      "i = 500/4096\tverts=500\ttime=791.4978244304657\n",
      "i = 600/4096\tverts=600\ttime=945.5785973072052\n",
      "i = 700/4096\tverts=700\ttime=1106.5557553768158\n",
      "i = 800/4096\tverts=800\ttime=1260.2444641590118\n",
      "i = 900/4096\tverts=900\ttime=1414.8863384723663\n",
      "i = 1000/4096\tverts=1000\ttime=1572.0981800556183\n",
      "i = 1100/4096\tverts=1100\ttime=1735.3753430843353\n",
      "i = 1200/4096\tverts=1200\ttime=1897.5189082622528\n",
      "i = 1300/4096\tverts=1300\ttime=2062.4106800556183\n",
      "i = 1400/4096\tverts=1400\ttime=2216.1803669929504\n",
      "i = 1500/4096\tverts=1500\ttime=2371.6837339401245\n",
      "i = 1600/4096\tverts=1600\ttime=2533.5381050109863\n",
      "i = 1700/4096\tverts=1700\ttime=2689.0825753211975\n",
      "i = 1800/4096\tverts=1800\ttime=2842.7331318855286\n",
      "i = 1900/4096\tverts=1900\ttime=2997.851731300354\n",
      "i = 2000/4096\tverts=2000\ttime=3158.2133696079254\n",
      "i = 2100/4096\tverts=2100\ttime=3311.481657266617\n",
      "i = 2200/4096\tverts=2200\ttime=3466.2734830379486\n",
      "i = 2300/4096\tverts=2300\ttime=3627.205829143524\n",
      "i = 2400/4096\tverts=2400\ttime=3784.900417804718\n",
      "i = 2500/4096\tverts=2500\ttime=3946.8051595687866\n",
      "i = 2600/4096\tverts=2600\ttime=4111.785048007965\n",
      "i = 2700/4096\tverts=2700\ttime=4269.3522782325745\n",
      "i = 2800/4096\tverts=2800\ttime=4426.692174911499\n",
      "i = 2900/4096\tverts=2900\ttime=4581.64880156517\n",
      "i = 3000/4096\tverts=3000\ttime=4745.168984889984\n",
      "i = 3100/4096\tverts=3100\ttime=4904.689016342163\n",
      "i = 3200/4096\tverts=3200\ttime=5064.326726436615\n",
      "i = 3300/4096\tverts=3300\ttime=5219.357124090195\n",
      "i = 3400/4096\tverts=3400\ttime=5374.266698598862\n",
      "i = 3500/4096\tverts=3500\ttime=5528.043114900589\n",
      "i = 3600/4096\tverts=3600\ttime=5682.319793701172\n",
      "i = 3700/4096\tverts=3700\ttime=5838.035163164139\n",
      "i = 3800/4096\tverts=3800\ttime=5991.83726978302\n",
      "i = 3900/4096\tverts=3900\ttime=6152.547833919525\n",
      "i = 4000/4096\tverts=4000\ttime=6312.937812328339\n",
      "i = 4096/4096\tverts=4096\ttime=6466.985724210739\n",
      "i = 1/2048\tverts=1\ttime=1.694171667098999\n",
      "i = 100/2048\tverts=100\ttime=169.2207806110382\n",
      "i = 200/2048\tverts=200\ttime=339.7860732078552\n",
      "i = 300/2048\tverts=300\ttime=509.2540090084076\n",
      "i = 400/2048\tverts=400\ttime=682.325446844101\n",
      "i = 500/2048\tverts=500\ttime=850.5417995452881\n",
      "i = 600/2048\tverts=600\ttime=1022.4186429977417\n",
      "i = 700/2048\tverts=700\ttime=1194.8014905452728\n",
      "i = 800/2048\tverts=800\ttime=1363.5826404094696\n",
      "i = 900/2048\tverts=900\ttime=1528.52712059021\n",
      "i = 1000/2048\tverts=1000\ttime=1693.3782708644867\n",
      "i = 1100/2048\tverts=1100\ttime=1862.7668752670288\n",
      "i = 1200/2048\tverts=1200\ttime=2039.3629360198975\n",
      "i = 1300/2048\tverts=1300\ttime=2213.686320543289\n",
      "i = 1400/2048\tverts=1400\ttime=2387.6405601501465\n",
      "i = 1500/2048\tverts=1500\ttime=2561.194278717041\n",
      "i = 1600/2048\tverts=1600\ttime=2736.912789583206\n",
      "i = 1700/2048\tverts=1700\ttime=2904.332185983658\n",
      "i = 1800/2048\tverts=1800\ttime=3078.1727318763733\n",
      "i = 1900/2048\tverts=1900\ttime=3250.6199078559875\n",
      "i = 2000/2048\tverts=2000\ttime=3415.865779876709\n",
      "i = 2048/2048\tverts=2048\ttime=3496.6460988521576\n",
      "i = 1/256\tverts=1\ttime=0.10658717155456543\n",
      "i = 100/256\tverts=100\ttime=10.86966323852539\n",
      "i = 200/256\tverts=200\ttime=21.76646375656128\n",
      "i = 256/256\tverts=256\ttime=27.848721981048584\n",
      "i = 1/512\tverts=1\ttime=0.45898938179016113\n",
      "i = 100/512\tverts=100\ttime=46.058263540267944\n",
      "i = 200/512\tverts=200\ttime=97.45370244979858\n",
      "i = 300/512\tverts=300\ttime=145.38574051856995\n",
      "i = 400/512\tverts=400\ttime=191.32298684120178\n",
      "i = 500/512\tverts=500\ttime=237.40309476852417\n",
      "i = 512/512\tverts=512\ttime=242.92200636863708\n",
      "i = 1/512\tverts=1\ttime=0.47324085235595703\n",
      "i = 100/512\tverts=100\ttime=45.88874053955078\n",
      "i = 200/512\tverts=200\ttime=91.96977114677429\n",
      "i = 300/512\tverts=300\ttime=141.206307888031\n",
      "i = 400/512\tverts=400\ttime=188.5235025882721\n",
      "i = 500/512\tverts=500\ttime=234.38952207565308\n",
      "i = 512/512\tverts=512\ttime=239.9401457309723\n",
      "[256, 4096, 2048, 256, 512, 512]\n",
      "[256, 4096, 2048, 256, 512, 512]\n"
     ]
    }
   ],
   "source": [
    "newFterms = []\n",
    "goodIndicesFull = []\n",
    "fullWs = []\n",
    "for i in range(0, len(Ftermsfull)-1, 2):\n",
    "    tempAdd = np.array(list(Ftermsfull[i]))\n",
    "    tempAdd2 = np.array(list(Ftermsfull[i+1]))\n",
    "    temp = multiplyTrops(tempAdd, tempAdd2)\n",
    "    \n",
    "    # There may be an odd number of terms - in that case, wrap the last in with the previous 2\n",
    "    if len(Ftermsfull) - 1 <= i+2:\n",
    "        tempAdd3 = np.array(list(Ftermsfull[i+2]))\n",
    "        temp = multiplyTrops(temp, tempAdd3)\n",
    "    \n",
    "    newFterms.append(temp)\n",
    "    ws, goodIndices = computeWs(temp, k=min(786, temp.shape[0]-1))\n",
    "    goodIndicesFull.append(goodIndices)\n",
    "    fullWs.append(ws)\n",
    "    \n",
    "print([val.shape[0] for val in newFterms])\n",
    "print([len(val) for val in goodIndicesFull])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 1/4096\tverts=1\ttime=3.5673720836639404\n",
      "i = 100/4096\tverts=100\ttime=365.65286684036255\n",
      "i = 200/4096\tverts=200\ttime=720.0447235107422\n",
      "i = 300/4096\tverts=300\ttime=1084.5185689926147\n",
      "i = 400/4096\tverts=400\ttime=1458.4401633739471\n",
      "i = 500/4096\tverts=500\ttime=1819.8820161819458\n",
      "i = 600/4096\tverts=600\ttime=2168.7433104515076\n",
      "i = 700/4096\tverts=700\ttime=2530.6758663654327\n",
      "i = 800/4096\tverts=800\ttime=2898.9037623405457\n",
      "i = 900/4096\tverts=900\ttime=3258.5181336402893\n",
      "i = 1000/4096\tverts=1000\ttime=3621.5378308296204\n",
      "i = 1100/4096\tverts=1100\ttime=3984.6942200660706\n",
      "i = 1200/4096\tverts=1200\ttime=4337.238765239716\n",
      "i = 1300/4096\tverts=1300\ttime=4695.868378639221\n",
      "i = 1400/4096\tverts=1400\ttime=5045.953987836838\n",
      "i = 1500/4096\tverts=1500\ttime=5405.806816577911\n",
      "i = 1600/4096\tverts=1600\ttime=5756.345547914505\n",
      "i = 1700/4096\tverts=1700\ttime=6119.721143722534\n",
      "i = 1800/4096\tverts=1800\ttime=6479.777388811111\n",
      "i = 1900/4096\tverts=1900\ttime=6840.853674173355\n",
      "i = 2000/4096\tverts=2000\ttime=7207.907062768936\n",
      "i = 2100/4096\tverts=2100\ttime=7554.17750453949\n",
      "i = 2200/4096\tverts=2200\ttime=7904.266759157181\n",
      "i = 2300/4096\tverts=2300\ttime=8245.222431898117\n",
      "i = 2400/4096\tverts=2400\ttime=8593.951781749725\n",
      "i = 2500/4096\tverts=2500\ttime=8966.885967731476\n",
      "i = 2600/4096\tverts=2600\ttime=9322.478986740112\n",
      "i = 2700/4096\tverts=2700\ttime=9665.342252016068\n",
      "i = 2800/4096\tverts=2800\ttime=10028.491221189499\n",
      "i = 2900/4096\tverts=2900\ttime=10399.58480477333\n",
      "i = 3000/4096\tverts=3000\ttime=10745.6689889431\n",
      "i = 3100/4096\tverts=3100\ttime=11116.966818094254\n",
      "i = 3200/4096\tverts=3200\ttime=11493.763179540634\n",
      "i = 3300/4096\tverts=3300\ttime=11843.40826702118\n",
      "i = 3400/4096\tverts=3400\ttime=12206.00912809372\n",
      "i = 3500/4096\tverts=3500\ttime=12582.345250368118\n",
      "i = 3600/4096\tverts=3600\ttime=12948.42122578621\n",
      "i = 3700/4096\tverts=3700\ttime=13319.140413045883\n",
      "i = 3800/4096\tverts=3800\ttime=13692.437813520432\n",
      "i = 3900/4096\tverts=3900\ttime=14043.014281749725\n",
      "i = 4000/4096\tverts=4000\ttime=14390.439954042435\n",
      "i = 4096/4096\tverts=4096\ttime=14733.373147726059\n",
      "i = 1/256\tverts=1\ttime=0.10697650909423828\n",
      "i = 100/256\tverts=100\ttime=10.931926727294922\n",
      "i = 200/256\tverts=200\ttime=21.88885259628296\n",
      "i = 256/256\tverts=256\ttime=27.944728136062622\n",
      "i = 1/512\tverts=1\ttime=0.4712231159210205\n",
      "i = 100/512\tverts=100\ttime=45.62647581100464\n",
      "i = 200/512\tverts=200\ttime=91.4773383140564\n",
      "i = 300/512\tverts=300\ttime=137.4835238456726\n",
      "i = 400/512\tverts=400\ttime=183.44899344444275\n",
      "i = 500/512\tverts=500\ttime=229.74623489379883\n",
      "i = 512/512\tverts=512\ttime=235.3792142868042\n",
      "i = 1/4096\tverts=1\ttime=3.2109265327453613\n",
      "i = 100/4096\tverts=100\ttime=340.42252826690674\n",
      "i = 200/4096\tverts=200\ttime=686.2886276245117\n",
      "i = 300/4096\tverts=300\ttime=1027.2894818782806\n",
      "i = 400/4096\tverts=400\ttime=1359.0703856945038\n",
      "i = 500/4096\tverts=500\ttime=1684.187929391861\n",
      "i = 600/4096\tverts=600\ttime=2024.045931339264\n",
      "i = 700/4096\tverts=700\ttime=2360.2311582565308\n",
      "i = 800/4096\tverts=800\ttime=2701.043907403946\n",
      "i = 900/4096\tverts=900\ttime=3046.858516931534\n",
      "i = 1000/4096\tverts=1000\ttime=3392.2232427597046\n",
      "i = 1100/4096\tverts=1100\ttime=3737.5045948028564\n",
      "i = 1200/4096\tverts=1200\ttime=4079.7324934005737\n",
      "i = 1300/4096\tverts=1300\ttime=4401.344476222992\n",
      "i = 1400/4096\tverts=1400\ttime=4723.119738340378\n",
      "i = 1500/4096\tverts=1500\ttime=5046.489459514618\n",
      "i = 1600/4096\tverts=1600\ttime=5367.458579301834\n",
      "i = 1700/4096\tverts=1700\ttime=5691.143580675125\n",
      "i = 1800/4096\tverts=1800\ttime=6031.856628894806\n",
      "i = 1900/4096\tverts=1900\ttime=6353.455518484116\n",
      "i = 2000/4096\tverts=2000\ttime=6675.423641204834\n",
      "i = 2100/4096\tverts=2100\ttime=7017.400510787964\n",
      "i = 2200/4096\tverts=2200\ttime=7363.599555492401\n",
      "i = 2300/4096\tverts=2300\ttime=7707.329326868057\n",
      "i = 2400/4096\tverts=2400\ttime=8042.121411323547\n",
      "i = 2500/4096\tverts=2500\ttime=8380.999086141586\n",
      "i = 2600/4096\tverts=2600\ttime=8702.280448675156\n",
      "i = 2700/4096\tverts=2700\ttime=9027.14729976654\n",
      "i = 2800/4096\tverts=2800\ttime=9372.481355190277\n",
      "i = 2900/4096\tverts=2900\ttime=9706.019309043884\n",
      "i = 3000/4096\tverts=3000\ttime=10050.324447870255\n",
      "i = 3100/4096\tverts=3100\ttime=10393.463970899582\n",
      "i = 3200/4096\tverts=3200\ttime=10733.760473966599\n",
      "i = 3300/4096\tverts=3300\ttime=11078.752797842026\n",
      "i = 3400/4096\tverts=3400\ttime=11419.931237697601\n",
      "i = 3500/4096\tverts=3500\ttime=11741.052568912506\n",
      "i = 3600/4096\tverts=3600\ttime=12068.747873544693\n",
      "i = 3700/4096\tverts=3700\ttime=12414.18225312233\n",
      "i = 3800/4096\tverts=3800\ttime=12738.87710595131\n",
      "i = 3900/4096\tverts=3900\ttime=13059.716980218887\n",
      "i = 4000/4096\tverts=4000\ttime=13400.667951345444\n",
      "i = 4096/4096\tverts=4096\ttime=13733.274522542953\n",
      "i = 1/2048\tverts=1\ttime=3.455144166946411\n",
      "i = 100/2048\tverts=100\ttime=366.26532888412476\n",
      "i = 200/2048\tverts=200\ttime=723.3142492771149\n",
      "i = 300/2048\tverts=300\ttime=1070.1135437488556\n",
      "i = 400/2048\tverts=400\ttime=1430.6781170368195\n",
      "i = 500/2048\tverts=500\ttime=1798.188393354416\n",
      "i = 600/2048\tverts=600\ttime=2136.673172235489\n",
      "i = 700/2048\tverts=700\ttime=2468.108285665512\n",
      "i = 800/2048\tverts=800\ttime=2834.43479847908\n",
      "i = 900/2048\tverts=900\ttime=3181.4975640773773\n",
      "i = 1000/2048\tverts=1000\ttime=3542.7990069389343\n",
      "i = 1100/2048\tverts=1100\ttime=3904.008729696274\n",
      "i = 1200/2048\tverts=1200\ttime=4262.313160896301\n",
      "i = 1300/2048\tverts=1300\ttime=4619.383437633514\n",
      "i = 1400/2048\tverts=1400\ttime=4970.442096710205\n",
      "i = 1500/2048\tverts=1500\ttime=5331.381051063538\n",
      "i = 1600/2048\tverts=1600\ttime=5689.83111166954\n",
      "i = 1700/2048\tverts=1700\ttime=6048.191277980804\n",
      "i = 1800/2048\tverts=1800\ttime=6399.061021327972\n",
      "i = 1900/2048\tverts=1900\ttime=6748.202024936676\n",
      "i = 2000/2048\tverts=2000\ttime=7107.957874298096\n",
      "i = 2048/2048\tverts=2048\ttime=7271.164967060089\n"
     ]
    }
   ],
   "source": [
    "newGterms = []\n",
    "goodIndicesFullG = []\n",
    "fullWsG = []\n",
    "for i in range(0, len(Gtermsfull)-1, 2):\n",
    "    tempAdd = np.array(list(Gtermsfull[i]))\n",
    "    tempAdd2 = np.array(list(Gtermsfull[i+1]))\n",
    "    temp = multiplyTrops(tempAdd, tempAdd2)\n",
    "    \n",
    "    # There may be an odd number of terms - in that case, wrap the last in with the previous 2\n",
    "    if len(Ftermsfull) - 1 <= i+2:\n",
    "        tempAdd2 = np.array(list(Gtermsfull[i+2]))\n",
    "        temp = multiplyTrops(temp, tempAdd2)\n",
    "    \n",
    "    newGterms.append(temp)\n",
    "    ws, goodIndices = computeWs(temp, k=min(1000, temp.shape[0]-1))\n",
    "    goodIndicesFullG.append(goodIndices)\n",
    "    fullWsG.append(ws)\n",
    "    \n",
    "print([val.shape[0] for val in newGterms])\n",
    "print([len(val) for val in goodIndicesFullG])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 1/65536\tverts=1\ttime=3.182948589324951\n",
      "i = 100/65536\tverts=97\ttime=313.57209968566895\n",
      "i = 200/65536\tverts=193\ttime=626.9816176891327\n",
      "i = 300/65536\tverts=291\ttime=934.8976018428802\n",
      "i = 400/65536\tverts=385\ttime=1242.9539551734924\n",
      "i = 500/65536\tverts=485\ttime=1558.6873517036438\n",
      "i = 600/65536\tverts=582\ttime=1856.3139126300812\n",
      "i = 700/65536\tverts=677\ttime=2165.697219848633\n",
      "i = 800/65536\tverts=777\ttime=2468.375405550003\n",
      "i = 900/65536\tverts=871\ttime=2776.136768579483\n",
      "i = 1000/65536\tverts=969\ttime=3092.1326949596405\n",
      "i = 1100/65536\tverts=1006\ttime=3395.798807144165\n",
      "i = 1200/65536\tverts=1024\ttime=3698.798754930496\n",
      "i = 1300/65536\tverts=1034\ttime=3996.8488540649414\n",
      "i = 1400/65536\tverts=1054\ttime=4291.096279621124\n",
      "i = 1500/65536\tverts=1069\ttime=4595.8072056770325\n",
      "i = 1600/65536\tverts=1084\ttime=4886.637312173843\n",
      "i = 1700/65536\tverts=1102\ttime=5192.1670796871185\n",
      "i = 1800/65536\tverts=1113\ttime=5486.083515882492\n",
      "i = 1900/65536\tverts=1133\ttime=5793.051257133484\n",
      "i = 2000/65536\tverts=1147\ttime=6102.012113332748\n",
      "i = 2100/65536\tverts=1162\ttime=6403.886331319809\n",
      "i = 2200/65536\tverts=1190\ttime=6720.0117127895355\n",
      "i = 2300/65536\tverts=1217\ttime=7037.409576654434\n",
      "i = 2400/65536\tverts=1237\ttime=7356.41132068634\n",
      "i = 2500/65536\tverts=1261\ttime=7685.620229244232\n",
      "i = 2600/65536\tverts=1280\ttime=8002.65683054924\n",
      "i = 2700/65536\tverts=1294\ttime=8316.001665353775\n",
      "i = 2800/65536\tverts=1308\ttime=8644.028806447983\n",
      "i = 2900/65536\tverts=1323\ttime=8967.6842315197\n",
      "i = 3000/65536\tverts=1342\ttime=9289.023063898087\n",
      "i = 3100/65536\tverts=1362\ttime=9597.899817228317\n",
      "i = 3200/65536\tverts=1374\ttime=9902.148889780045\n",
      "i = 3300/65536\tverts=1391\ttime=10207.39233660698\n",
      "i = 3400/65536\tverts=1400\ttime=10506.531738519669\n",
      "i = 3500/65536\tverts=1417\ttime=10810.993475198746\n",
      "i = 3600/65536\tverts=1431\ttime=11118.215312957764\n",
      "i = 3700/65536\tverts=1436\ttime=11425.616429328918\n",
      "i = 3800/65536\tverts=1450\ttime=11722.476805448532\n",
      "i = 3900/65536\tverts=1458\ttime=12021.04776597023\n",
      "i = 4000/65536\tverts=1470\ttime=12329.532857656479\n",
      "i = 4100/65536\tverts=1484\ttime=12627.83437037468\n",
      "i = 4200/65536\tverts=1490\ttime=12952.117210388184\n",
      "i = 4300/65536\tverts=1498\ttime=13285.412496089935\n",
      "i = 4400/65536\tverts=1506\ttime=13626.55094575882\n",
      "i = 4500/65536\tverts=1511\ttime=13952.10518693924\n",
      "i = 4600/65536\tverts=1515\ttime=14281.383689880371\n",
      "i = 4700/65536\tverts=1519\ttime=14602.779606103897\n",
      "i = 4800/65536\tverts=1522\ttime=14922.242796182632\n",
      "i = 4900/65536\tverts=1527\ttime=15262.74932050705\n",
      "i = 5000/65536\tverts=1530\ttime=15588.78624176979\n",
      "i = 5100/65536\tverts=1537\ttime=15921.952005386353\n",
      "i = 5200/65536\tverts=1549\ttime=16231.744790792465\n",
      "i = 5300/65536\tverts=1555\ttime=16538.010786533356\n",
      "i = 5400/65536\tverts=1567\ttime=16837.961131572723\n",
      "i = 5500/65536\tverts=1582\ttime=17145.94645667076\n",
      "i = 5600/65536\tverts=1592\ttime=17446.789682388306\n",
      "i = 5700/65536\tverts=1602\ttime=17744.885725736618\n",
      "i = 5800/65536\tverts=1615\ttime=18038.30475473404\n",
      "i = 5900/65536\tverts=1624\ttime=18344.0272462368\n",
      "i = 6000/65536\tverts=1634\ttime=18655.98098397255\n",
      "i = 6100/65536\tverts=1640\ttime=18965.025939702988\n",
      "i = 6200/65536\tverts=1660\ttime=19269.376854896545\n",
      "i = 6300/65536\tverts=1693\ttime=19568.968683242798\n",
      "i = 6400/65536\tverts=1724\ttime=19868.618792295456\n",
      "i = 6500/65536\tverts=1757\ttime=20175.67886543274\n",
      "i = 6600/65536\tverts=1790\ttime=20480.287435293198\n",
      "i = 6700/65536\tverts=1823\ttime=20782.033583641052\n",
      "i = 6800/65536\tverts=1853\ttime=21087.418384313583\n",
      "i = 6900/65536\tverts=1882\ttime=21390.94526720047\n",
      "i = 7000/65536\tverts=1914\ttime=21691.45596933365\n",
      "i = 7100/65536\tverts=1947\ttime=21998.09913086891\n",
      "i = 7200/65536\tverts=1975\ttime=22301.79108762741\n",
      "i = 7300/65536\tverts=1988\ttime=22624.96816134453\n",
      "i = 7400/65536\tverts=2002\ttime=22965.927003383636\n",
      "i = 7500/65536\tverts=2012\ttime=23296.774227380753\n",
      "i = 7600/65536\tverts=2020\ttime=23616.774396896362\n",
      "i = 7700/65536\tverts=2023\ttime=23941.243718862534\n",
      "i = 7800/65536\tverts=2027\ttime=24271.653239250183\n",
      "i = 7900/65536\tverts=2031\ttime=24594.01334118843\n",
      "i = 8000/65536\tverts=2035\ttime=24911.89184975624\n",
      "i = 8100/65536\tverts=2040\ttime=25239.348574399948\n",
      "i = 8200/65536\tverts=2044\ttime=25567.99903321266\n",
      "i = 8300/65536\tverts=2064\ttime=25862.38288450241\n",
      "i = 8400/65536\tverts=2078\ttime=26163.88474369049\n",
      "i = 8500/65536\tverts=2091\ttime=26460.089280843735\n",
      "i = 8600/65536\tverts=2112\ttime=26766.535798549652\n",
      "i = 8700/65536\tverts=2123\ttime=27068.764492034912\n",
      "i = 8800/65536\tverts=2140\ttime=27368.36474084854\n",
      "i = 8900/65536\tverts=2157\ttime=27661.413650274277\n",
      "i = 9000/65536\tverts=2168\ttime=27958.273896694183\n",
      "i = 9100/65536\tverts=2190\ttime=28256.793689727783\n",
      "i = 9200/65536\tverts=2202\ttime=28565.497435331345\n",
      "i = 9300/65536\tverts=2285\ttime=28871.200429439545\n",
      "i = 9400/65536\tverts=2381\ttime=29184.447949171066\n",
      "i = 9500/65536\tverts=2480\ttime=29500.038053035736\n",
      "i = 9600/65536\tverts=2574\ttime=29802.507362365723\n",
      "i = 9700/65536\tverts=2672\ttime=30107.953193426132\n",
      "i = 9800/65536\tverts=2772\ttime=30411.54216647148\n",
      "i = 9900/65536\tverts=2865\ttime=30713.324821710587\n",
      "i = 10000/65536\tverts=2964\ttime=31020.171416044235\n",
      "i = 10100/65536\tverts=3061\ttime=31337.46773123741\n",
      "i = 10200/65536\tverts=3157\ttime=31649.08505344391\n",
      "i = 10300/65536\tverts=3215\ttime=31955.42487502098\n",
      "i = 10400/65536\tverts=3247\ttime=32253.901909828186\n",
      "i = 10500/65536\tverts=3278\ttime=32556.100959539413\n",
      "i = 10600/65536\tverts=3311\ttime=32853.300662755966\n",
      "i = 10700/65536\tverts=3343\ttime=33149.701214551926\n",
      "i = 10800/65536\tverts=3377\ttime=33457.462693691254\n",
      "i = 10900/65536\tverts=3406\ttime=33765.88086223602\n",
      "i = 11000/65536\tverts=3436\ttime=34070.85036802292\n",
      "i = 11100/65536\tverts=3468\ttime=34363.358753204346\n",
      "i = 11200/65536\tverts=3503\ttime=34662.43900060654\n",
      "i = 11300/65536\tverts=3526\ttime=34974.97167825699\n",
      "i = 11400/65536\tverts=3528\ttime=35298.600935935974\n",
      "i = 11500/65536\tverts=3532\ttime=35619.09494185448\n",
      "i = 11600/65536\tverts=3539\ttime=35945.47123122215\n",
      "i = 11700/65536\tverts=3540\ttime=36273.126504182816\n",
      "i = 11800/65536\tverts=3546\ttime=36596.50239300728\n",
      "i = 11900/65536\tverts=3554\ttime=36933.74407410622\n",
      "i = 12000/65536\tverts=3563\ttime=37263.741701602936\n",
      "i = 12100/65536\tverts=3567\ttime=37590.91648077965\n",
      "i = 12200/65536\tverts=3572\ttime=37909.13740158081\n",
      "i = 12300/65536\tverts=3577\ttime=38232.286964416504\n",
      "i = 12400/65536\tverts=3585\ttime=38530.80617761612\n",
      "i = 12500/65536\tverts=3593\ttime=38832.91937971115\n",
      "i = 12600/65536\tverts=3609\ttime=39129.97245883942\n",
      "i = 12700/65536\tverts=3620\ttime=39439.34372591972\n",
      "i = 12800/65536\tverts=3632\ttime=39747.04152035713\n",
      "i = 12900/65536\tverts=3643\ttime=40050.96494412422\n",
      "i = 13000/65536\tverts=3654\ttime=40354.58302330971\n",
      "i = 13100/65536\tverts=3671\ttime=40656.919731616974\n",
      "i = 13200/65536\tverts=3684\ttime=40963.37578034401\n",
      "i = 13300/65536\tverts=3696\ttime=41263.555981874466\n",
      "i = 13400/65536\tverts=3704\ttime=41578.64464068413\n",
      "i = 13500/65536\tverts=3705\ttime=41909.15788912773\n",
      "i = 13600/65536\tverts=3709\ttime=42239.06539726257\n",
      "i = 13700/65536\tverts=3715\ttime=42570.47897982597\n",
      "i = 13800/65536\tverts=3720\ttime=42900.25016570091\n",
      "i = 13900/65536\tverts=3731\ttime=43229.16381955147\n",
      "i = 14000/65536\tverts=3746\ttime=43549.60815238953\n",
      "i = 14100/65536\tverts=3757\ttime=43880.44587445259\n",
      "i = 14200/65536\tverts=3764\ttime=44211.23397564888\n",
      "i = 14300/65536\tverts=3772\ttime=44545.284093141556\n",
      "i = 14400/65536\tverts=3785\ttime=44865.16206288338\n",
      "i = 14500/65536\tverts=3795\ttime=45181.91925263405\n",
      "i = 14600/65536\tverts=3809\ttime=45505.16164278984\n",
      "i = 14700/65536\tverts=3827\ttime=45831.10962843895\n",
      "i = 14800/65536\tverts=3847\ttime=46148.2197637558\n",
      "i = 14900/65536\tverts=3872\ttime=46462.521664619446\n",
      "i = 15000/65536\tverts=3894\ttime=46784.450419187546\n",
      "i = 15100/65536\tverts=3919\ttime=47109.29074835777\n",
      "i = 15200/65536\tverts=3942\ttime=47432.0222427845\n",
      "i = 15300/65536\tverts=3961\ttime=47754.153445243835\n",
      "i = 15400/65536\tverts=3983\ttime=48071.04909801483\n",
      "i = 15500/65536\tverts=3995\ttime=48369.979927778244\n",
      "i = 15600/65536\tverts=4006\ttime=48672.46020293236\n",
      "i = 15700/65536\tverts=4013\ttime=48981.99074959755\n",
      "i = 15800/65536\tverts=4020\ttime=49282.01902127266\n",
      "i = 15900/65536\tverts=4030\ttime=49578.09706258774\n",
      "i = 16000/65536\tverts=4039\ttime=49876.137946128845\n",
      "i = 16100/65536\tverts=4051\ttime=50169.40991330147\n",
      "i = 16200/65536\tverts=4063\ttime=50462.70141887665\n",
      "i = 16300/65536\tverts=4076\ttime=50770.976726293564\n",
      "i = 16400/65536\tverts=4087\ttime=51084.17862415314\n",
      "i = 16500/65536\tverts=4110\ttime=51409.996024131775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 16600/65536\tverts=4139\ttime=51732.70277619362\n",
      "i = 16700/65536\tverts=4159\ttime=52065.92827820778\n",
      "i = 16800/65536\tverts=4183\ttime=52392.397146224976\n",
      "i = 16900/65536\tverts=4207\ttime=52714.68871951103\n",
      "i = 17000/65536\tverts=4220\ttime=53046.77878499031\n",
      "i = 17100/65536\tverts=4235\ttime=53373.85959839821\n",
      "i = 17200/65536\tverts=4247\ttime=53707.44296312332\n",
      "i = 17300/65536\tverts=4268\ttime=54029.14952707291\n",
      "i = 17400/65536\tverts=4289\ttime=54349.36410212517\n",
      "i = 17500/65536\tverts=4320\ttime=54658.121846199036\n",
      "i = 17600/65536\tverts=4351\ttime=54955.162558078766\n",
      "i = 17700/65536\tverts=4384\ttime=55264.399864435196\n",
      "i = 17800/65536\tverts=4417\ttime=55569.08432006836\n",
      "i = 17900/65536\tverts=4447\ttime=55875.18064188957\n",
      "i = 18000/65536\tverts=4479\ttime=56168.32724428177\n",
      "i = 18100/65536\tverts=4508\ttime=56470.907829999924\n",
      "i = 18200/65536\tverts=4540\ttime=56776.23694586754\n",
      "i = 18300/65536\tverts=4571\ttime=57081.98174905777\n",
      "i = 18400/65536\tverts=4607\ttime=57392.35288286209\n",
      "i = 18500/65536\tverts=4682\ttime=57693.44399333\n",
      "i = 18600/65536\tverts=4782\ttime=57992.847017765045\n",
      "i = 18700/65536\tverts=4882\ttime=58284.515296936035\n",
      "i = 18800/65536\tverts=4978\ttime=58583.886404037476\n",
      "i = 18900/65536\tverts=5076\ttime=58878.82121229172\n",
      "i = 19000/65536\tverts=5172\ttime=59176.285137176514\n",
      "i = 19100/65536\tverts=5270\ttime=59492.3098692894\n",
      "i = 19200/65536\tverts=5369\ttime=59801.5838663578\n",
      "i = 19300/65536\tverts=5464\ttime=60122.29220843315\n",
      "i = 19400/65536\tverts=5563\ttime=60428.62309551239\n",
      "i = 19500/65536\tverts=5627\ttime=60748.60750603676\n",
      "i = 19600/65536\tverts=5639\ttime=61076.529855012894\n",
      "i = 19700/65536\tverts=5652\ttime=61396.37946534157\n",
      "i = 19800/65536\tverts=5662\ttime=61715.68797707558\n",
      "i = 19900/65536\tverts=5669\ttime=62054.71397471428\n",
      "i = 20000/65536\tverts=5674\ttime=62394.06482553482\n",
      "i = 20100/65536\tverts=5676\ttime=62724.32314968109\n",
      "i = 20200/65536\tverts=5680\ttime=63052.71288061142\n",
      "i = 20300/65536\tverts=5684\ttime=63385.305869579315\n",
      "i = 20400/65536\tverts=5689\ttime=63715.949142456055\n",
      "i = 20500/65536\tverts=5696\ttime=64046.927157878876\n",
      "i = 20600/65536\tverts=5710\ttime=64357.98300862312\n",
      "i = 20700/65536\tverts=5715\ttime=64663.782811403275\n",
      "i = 20800/65536\tverts=5731\ttime=64970.31284737587\n",
      "i = 20900/65536\tverts=5741\ttime=65278.56768965721\n",
      "i = 21000/65536\tverts=5751\ttime=65591.25660657883\n",
      "i = 21100/65536\tverts=5762\ttime=65905.52653241158\n",
      "i = 21200/65536\tverts=5774\ttime=66215.94531321526\n",
      "i = 21300/65536\tverts=5783\ttime=66510.4467458725\n",
      "i = 21400/65536\tverts=5792\ttime=66810.81766200066\n",
      "i = 21500/65536\tverts=5800\ttime=67120.50209975243\n",
      "i = 21600/65536\tverts=5806\ttime=67442.1236064434\n",
      "i = 21700/65536\tverts=5814\ttime=67780.27812504768\n",
      "i = 21800/65536\tverts=5823\ttime=68111.33296394348\n",
      "i = 21900/65536\tverts=5829\ttime=68433.11475300789\n",
      "i = 22000/65536\tverts=5833\ttime=68755.43699407578\n",
      "i = 22100/65536\tverts=5835\ttime=69073.75382733345\n",
      "i = 22200/65536\tverts=5840\ttime=69397.45479631424\n",
      "i = 22300/65536\tverts=5845\ttime=69739.17843961716\n",
      "i = 22400/65536\tverts=5848\ttime=70061.77395534515\n",
      "i = 22500/65536\tverts=5855\ttime=70403.5656516552\n",
      "i = 22600/65536\tverts=5867\ttime=70710.63069820404\n",
      "i = 22700/65536\tverts=5885\ttime=70998.59222865105\n",
      "i = 22800/65536\tverts=5896\ttime=71294.05834770203\n",
      "i = 22900/65536\tverts=5916\ttime=71595.79186797142\n",
      "i = 23000/65536\tverts=5931\ttime=71895.03008127213\n",
      "i = 23100/65536\tverts=5944\ttime=72193.14419937134\n",
      "i = 23200/65536\tverts=5964\ttime=72484.71813559532\n",
      "i = 23300/65536\tverts=5975\ttime=72784.47773241997\n",
      "i = 23400/65536\tverts=5993\ttime=73085.73512172699\n",
      "i = 23500/65536\tverts=6009\ttime=73376.24664735794\n",
      "i = 23600/65536\tverts=6019\ttime=73678.03796577454\n",
      "i = 23700/65536\tverts=6030\ttime=73986.46644759178\n",
      "i = 23800/65536\tverts=6048\ttime=74287.09824585915\n",
      "i = 23900/65536\tverts=6058\ttime=74576.17807364464\n",
      "i = 24000/65536\tverts=6079\ttime=74873.33062243462\n",
      "i = 24100/65536\tverts=6087\ttime=75175.43483686447\n",
      "i = 24200/65536\tverts=6096\ttime=75470.44247150421\n",
      "i = 24300/65536\tverts=6105\ttime=75763.1186747551\n",
      "i = 24400/65536\tverts=6117\ttime=76071.61798930168\n",
      "i = 24500/65536\tverts=6128\ttime=76373.13826704025\n",
      "i = 24600/65536\tverts=6140\ttime=76678.77242326736\n",
      "i = 24700/65536\tverts=6152\ttime=76980.0294084549\n",
      "i = 24800/65536\tverts=6168\ttime=77280.77458357811\n",
      "i = 24900/65536\tverts=6177\ttime=77578.06863904\n",
      "i = 25000/65536\tverts=6194\ttime=77883.55061030388\n",
      "i = 25100/65536\tverts=6209\ttime=78185.71691894531\n",
      "i = 25200/65536\tverts=6214\ttime=78482.77326989174\n",
      "i = 25300/65536\tverts=6228\ttime=78781.06975364685\n",
      "i = 25400/65536\tverts=6236\ttime=79079.71999406815\n",
      "i = 25500/65536\tverts=6247\ttime=79382.79487466812\n",
      "i = 25600/65536\tverts=6261\ttime=79683.05817604065\n",
      "i = 25700/65536\tverts=6265\ttime=80003.7851896286\n",
      "i = 25800/65536\tverts=6269\ttime=80341.39399957657\n",
      "i = 25900/65536\tverts=6275\ttime=80682.86232638359\n",
      "i = 26000/65536\tverts=6277\ttime=81014.17230534554\n",
      "i = 26100/65536\tverts=6279\ttime=81349.43654608727\n",
      "i = 26200/65536\tverts=6291\ttime=81671.19692707062\n",
      "i = 26300/65536\tverts=6298\ttime=82000.63067102432\n",
      "i = 26400/65536\tverts=6304\ttime=82319.10210371017\n",
      "i = 26500/65536\tverts=6309\ttime=82640.61153197289\n",
      "i = 26600/65536\tverts=6314\ttime=82963.9575457573\n",
      "i = 26700/65536\tverts=6326\ttime=83291.29850411415\n",
      "i = 26800/65536\tverts=6339\ttime=83626.8396229744\n",
      "i = 26900/65536\tverts=6351\ttime=83956.36277985573\n",
      "i = 27000/65536\tverts=6360\ttime=84275.66198444366\n",
      "i = 27100/65536\tverts=6366\ttime=84612.9066722393\n",
      "i = 27200/65536\tverts=6371\ttime=84942.20343470573\n",
      "i = 27300/65536\tverts=6374\ttime=85279.3664162159\n",
      "i = 27400/65536\tverts=6376\ttime=85605.92620253563\n",
      "i = 27500/65536\tverts=6381\ttime=85929.94601488113\n",
      "i = 27600/65536\tverts=6386\ttime=86271.15441608429\n",
      "i = 27700/65536\tverts=6441\ttime=86597.02441549301\n",
      "i = 27800/65536\tverts=6540\ttime=86894.97295284271\n",
      "i = 27900/65536\tverts=6638\ttime=87196.37817525864\n",
      "i = 28000/65536\tverts=6736\ttime=87496.90340948105\n",
      "i = 28100/65536\tverts=6834\ttime=87799.78899717331\n",
      "i = 28200/65536\tverts=6933\ttime=88107.57355570793\n",
      "i = 28300/65536\tverts=7022\ttime=88415.24574947357\n",
      "i = 28400/65536\tverts=7116\ttime=88713.04295611382\n",
      "i = 28500/65536\tverts=7213\ttime=89024.33895850182\n",
      "i = 28600/65536\tverts=7310\ttime=89337.9243683815\n",
      "i = 28700/65536\tverts=7383\ttime=89649.17147445679\n",
      "i = 28800/65536\tverts=7405\ttime=89948.83318328857\n",
      "i = 28900/65536\tverts=7417\ttime=90241.53632616997\n",
      "i = 29000/65536\tverts=7433\ttime=90547.42595911026\n",
      "i = 29100/65536\tverts=7451\ttime=90854.68264937401\n",
      "i = 29200/65536\tverts=7462\ttime=91143.89012742043\n",
      "i = 29300/65536\tverts=7482\ttime=91435.75558924675\n",
      "i = 29400/65536\tverts=7497\ttime=91732.91365504265\n",
      "i = 29500/65536\tverts=7510\ttime=92033.92790365219\n",
      "i = 29600/65536\tverts=7530\ttime=92331.66586112976\n",
      "i = 29700/65536\tverts=7542\ttime=92625.37470722198\n",
      "i = 29800/65536\tverts=7573\ttime=92918.64316606522\n",
      "i = 29900/65536\tverts=7606\ttime=93212.44556617737\n",
      "i = 30000/65536\tverts=7637\ttime=93502.80814957619\n",
      "i = 30100/65536\tverts=7669\ttime=93806.19136738777\n",
      "i = 30200/65536\tverts=7700\ttime=94118.17017436028\n",
      "i = 30300/65536\tverts=7733\ttime=94424.65591526031\n",
      "i = 30400/65536\tverts=7765\ttime=94727.8311958313\n",
      "i = 30500/65536\tverts=7797\ttime=95030.02220797539\n",
      "i = 30600/65536\tverts=7826\ttime=95333.50599241257\n",
      "i = 30700/65536\tverts=7861\ttime=95638.12892055511\n",
      "i = 30800/65536\tverts=7879\ttime=95937.31205391884\n",
      "i = 30900/65536\tverts=7889\ttime=96241.3389968872\n",
      "i = 31000/65536\tverts=7898\ttime=96542.59241843224\n",
      "i = 31100/65536\tverts=7905\ttime=96837.04994297028\n",
      "i = 31200/65536\tverts=7915\ttime=97141.86137866974\n",
      "i = 31300/65536\tverts=7924\ttime=97437.20754218102\n",
      "i = 31400/65536\tverts=7935\ttime=97744.5243833065\n",
      "i = 31500/65536\tverts=7944\ttime=98045.38450360298\n",
      "i = 31600/65536\tverts=7957\ttime=98344.8073964119\n",
      "i = 31700/65536\tverts=7970\ttime=98653.04710197449\n",
      "i = 31800/65536\tverts=7979\ttime=98960.60547876358\n",
      "i = 31900/65536\tverts=7990\ttime=99274.43565225601\n",
      "i = 32000/65536\tverts=8001\ttime=99606.30092215538\n",
      "i = 32100/65536\tverts=8013\ttime=99917.32072591782\n",
      "i = 32200/65536\tverts=8023\ttime=100240.6410279274\n",
      "i = 32300/65536\tverts=8034\ttime=100569.98935818672\n",
      "i = 32400/65536\tverts=8048\ttime=100892.14859223366\n",
      "i = 32500/65536\tverts=8058\ttime=101214.53452420235\n",
      "i = 32600/65536\tverts=8070\ttime=101532.28114295006\n",
      "i = 32700/65536\tverts=8079\ttime=101852.87697124481\n",
      "i = 32800/65536\tverts=8088\ttime=102186.99379038811\n",
      "i = 32900/65536\tverts=8095\ttime=102520.81359052658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 33000/65536\tverts=8105\ttime=102860.89912629128\n",
      "i = 33100/65536\tverts=8111\ttime=103185.72646927834\n",
      "i = 33200/65536\tverts=8117\ttime=103513.46689987183\n",
      "i = 33300/65536\tverts=8119\ttime=103840.80813908577\n",
      "i = 33400/65536\tverts=8124\ttime=104166.36252427101\n",
      "i = 33500/65536\tverts=8129\ttime=104497.8814690113\n",
      "i = 33600/65536\tverts=8131\ttime=104825.99758267403\n",
      "i = 33700/65536\tverts=8134\ttime=105164.43039369583\n",
      "i = 33800/65536\tverts=8141\ttime=105488.67664980888\n",
      "i = 33900/65536\tverts=8149\ttime=105796.97510075569\n",
      "i = 34000/65536\tverts=8157\ttime=106100.3727042675\n",
      "i = 34100/65536\tverts=8171\ttime=106393.37444472313\n",
      "i = 34200/65536\tverts=8184\ttime=106697.68911647797\n",
      "i = 34300/65536\tverts=8196\ttime=106999.70196080208\n",
      "i = 34400/65536\tverts=8207\ttime=107292.44409823418\n",
      "i = 34500/65536\tverts=8217\ttime=107583.57112121582\n",
      "i = 34600/65536\tverts=8233\ttime=107876.2711865902\n",
      "i = 34700/65536\tverts=8247\ttime=108184.33309721947\n",
      "i = 34800/65536\tverts=8258\ttime=108479.59762525558\n",
      "i = 34900/65536\tverts=8276\ttime=108789.01363301277\n",
      "i = 35000/65536\tverts=8283\ttime=109095.00413942337\n",
      "i = 35100/65536\tverts=8295\ttime=109409.0048046112\n",
      "i = 35200/65536\tverts=8309\ttime=109715.27308154106\n",
      "i = 35300/65536\tverts=8319\ttime=110019.54679441452\n",
      "i = 35400/65536\tverts=8330\ttime=110329.45117712021\n",
      "i = 35500/65536\tverts=8342\ttime=110636.6723036766\n",
      "i = 35600/65536\tverts=8353\ttime=110945.60947465897\n",
      "i = 35700/65536\tverts=8361\ttime=111240.85308289528\n",
      "i = 35800/65536\tverts=8367\ttime=111542.04433393478\n",
      "i = 35900/65536\tverts=8380\ttime=111835.24380135536\n",
      "i = 36000/65536\tverts=8400\ttime=112122.38454532623\n",
      "i = 36100/65536\tverts=8411\ttime=112424.44726872444\n",
      "i = 36200/65536\tverts=8429\ttime=112727.44512701035\n",
      "i = 36300/65536\tverts=8445\ttime=113018.29803872108\n",
      "i = 36400/65536\tverts=8456\ttime=113307.61355543137\n",
      "i = 36500/65536\tverts=8478\ttime=113604.47506427765\n",
      "i = 36600/65536\tverts=8489\ttime=113892.07580733299\n",
      "i = 36700/65536\tverts=8506\ttime=114197.56251907349\n",
      "i = 36800/65536\tverts=8524\ttime=114492.57657337189\n",
      "i = 36900/65536\tverts=8566\ttime=114796.62857294083\n",
      "i = 37000/65536\tverts=8655\ttime=115090.69263982773\n",
      "i = 37100/65536\tverts=8751\ttime=115387.69186878204\n",
      "i = 37200/65536\tverts=8847\ttime=115687.94698429108\n",
      "i = 37300/65536\tverts=8943\ttime=116000.09767651558\n",
      "i = 37400/65536\tverts=9042\ttime=116295.47069001198\n",
      "i = 37500/65536\tverts=9139\ttime=116598.84007906914\n",
      "i = 37600/65536\tverts=9239\ttime=116899.92199206352\n",
      "i = 37700/65536\tverts=9338\ttime=117207.09220480919\n",
      "i = 37800/65536\tverts=9435\ttime=117518.03675460815\n",
      "i = 37900/65536\tverts=9524\ttime=117821.37775921822\n",
      "i = 38000/65536\tverts=9534\ttime=118146.43977069855\n",
      "i = 38100/65536\tverts=9549\ttime=118467.04144310951\n",
      "i = 38200/65536\tverts=9560\ttime=118781.4618062973\n",
      "i = 38300/65536\tverts=9572\ttime=119099.07380509377\n",
      "i = 38400/65536\tverts=9579\ttime=119414.20325899124\n",
      "i = 38500/65536\tverts=9588\ttime=119731.71427559853\n",
      "i = 38600/65536\tverts=9601\ttime=120048.39919233322\n",
      "i = 38700/65536\tverts=9610\ttime=120373.45483779907\n",
      "i = 38800/65536\tverts=9621\ttime=120696.2667195797\n",
      "i = 38900/65536\tverts=9636\ttime=121016.27022767067\n",
      "i = 39000/65536\tverts=9640\ttime=121345.77498912811\n",
      "i = 39100/65536\tverts=9641\ttime=121677.07088828087\n",
      "i = 39200/65536\tverts=9645\ttime=122009.95913553238\n",
      "i = 39300/65536\tverts=9651\ttime=122344.49056768417\n",
      "i = 39400/65536\tverts=9656\ttime=122674.5231142044\n",
      "i = 39500/65536\tverts=9667\ttime=122994.94830536842\n",
      "i = 39600/65536\tverts=9682\ttime=123329.33058929443\n",
      "i = 39700/65536\tverts=9693\ttime=123658.22079205513\n",
      "i = 39800/65536\tverts=9700\ttime=123993.45568203926\n",
      "i = 39900/65536\tverts=9708\ttime=124323.76061034203\n",
      "i = 40000/65536\tverts=9728\ttime=124630.20840620995\n",
      "i = 40100/65536\tverts=9761\ttime=124929.81713819504\n",
      "i = 40200/65536\tverts=9792\ttime=125236.3565838337\n",
      "i = 40300/65536\tverts=9824\ttime=125534.04524850845\n",
      "i = 40400/65536\tverts=9857\ttime=125835.60328507423\n",
      "i = 40500/65536\tverts=9890\ttime=126147.53328728676\n",
      "i = 40600/65536\tverts=9921\ttime=126447.22130513191\n",
      "i = 40700/65536\tverts=9951\ttime=126739.8381228447\n",
      "i = 40800/65536\tverts=9983\ttime=127035.93119239807\n",
      "i = 40900/65536\tverts=10018\ttime=127342.63233709335\n",
      "i = 41000/65536\tverts=10043\ttime=127638.54745006561\n",
      "i = 41100/65536\tverts=10053\ttime=127934.69205451012\n",
      "i = 41200/65536\tverts=10061\ttime=128228.34893131256\n",
      "i = 41300/65536\tverts=10077\ttime=128531.21595668793\n",
      "i = 41400/65536\tverts=10085\ttime=128845.16549110413\n",
      "i = 41500/65536\tverts=10096\ttime=129159.63862848282\n",
      "i = 41600/65536\tverts=10108\ttime=129463.96555423737\n",
      "i = 41700/65536\tverts=10119\ttime=129758.71362686157\n",
      "i = 41800/65536\tverts=10127\ttime=130054.80894184113\n",
      "i = 41900/65536\tverts=10135\ttime=130362.60133934021\n",
      "i = 42000/65536\tverts=10144\ttime=130680.04032087326\n",
      "i = 42100/65536\tverts=10147\ttime=131005.47928786278\n",
      "i = 42200/65536\tverts=10150\ttime=131331.53497433662\n",
      "i = 42300/65536\tverts=10153\ttime=131656.67585873604\n",
      "i = 42400/65536\tverts=10159\ttime=131996.92068743706\n",
      "i = 42500/65536\tverts=10164\ttime=132329.2602713108\n",
      "i = 42600/65536\tverts=10178\ttime=132652.18680644035\n",
      "i = 42700/65536\tverts=10193\ttime=132982.49876260757\n",
      "i = 42800/65536\tverts=10201\ttime=133309.53037714958\n",
      "i = 42900/65536\tverts=10209\ttime=133641.09286737442\n",
      "i = 43000/65536\tverts=10217\ttime=133968.67927861214\n",
      "i = 43100/65536\tverts=10223\ttime=134293.73153948784\n",
      "i = 43200/65536\tverts=10231\ttime=134624.56265449524\n",
      "i = 43300/65536\tverts=10240\ttime=134957.35974168777\n",
      "i = 43400/65536\tverts=10245\ttime=135296.7622320652\n",
      "i = 43500/65536\tverts=10250\ttime=135633.78757238388\n",
      "i = 43600/65536\tverts=10252\ttime=135968.87318611145\n",
      "i = 43700/65536\tverts=10257\ttime=136288.63698744774\n",
      "i = 43800/65536\tverts=10262\ttime=136624.82012295723\n",
      "i = 43900/65536\tverts=10265\ttime=136955.88638663292\n",
      "i = 44000/65536\tverts=10272\ttime=137283.54197955132\n",
      "i = 44100/65536\tverts=10293\ttime=137587.16546082497\n",
      "i = 44200/65536\tverts=10324\ttime=137892.44505643845\n",
      "i = 44300/65536\tverts=10354\ttime=138204.71339130402\n",
      "i = 44400/65536\tverts=10388\ttime=138495.70952033997\n",
      "i = 44500/65536\tverts=10420\ttime=138805.6722021103\n",
      "i = 44600/65536\tverts=10453\ttime=139113.52397322655\n",
      "i = 44700/65536\tverts=10484\ttime=139405.53343343735\n",
      "i = 44800/65536\tverts=10515\ttime=139712.4790968895\n",
      "i = 44900/65536\tverts=10546\ttime=140015.05418729782\n",
      "i = 45000/65536\tverts=10580\ttime=140318.47370553017\n",
      "i = 45100/65536\tverts=10603\ttime=140637.0589888096\n",
      "i = 45200/65536\tverts=10615\ttime=140953.1328918934\n",
      "i = 45300/65536\tverts=10627\ttime=141267.81320810318\n",
      "i = 45400/65536\tverts=10636\ttime=141592.1529147625\n",
      "i = 45500/65536\tverts=10651\ttime=141903.8158724308\n",
      "i = 45600/65536\tverts=10658\ttime=142228.75026226044\n",
      "i = 45700/65536\tverts=10666\ttime=142557.4180779457\n",
      "i = 45800/65536\tverts=10680\ttime=142886.8483505249\n",
      "i = 45900/65536\tverts=10689\ttime=143221.76784086227\n",
      "i = 46000/65536\tverts=10701\ttime=143553.67672848701\n",
      "i = 46100/65536\tverts=10729\ttime=143872.81993842125\n",
      "i = 46200/65536\tverts=10821\ttime=144167.98628354073\n",
      "i = 46300/65536\tverts=10913\ttime=144462.51859092712\n",
      "i = 46400/65536\tverts=11008\ttime=144760.98258686066\n",
      "i = 46500/65536\tverts=11102\ttime=145068.03132748604\n",
      "i = 46600/65536\tverts=11201\ttime=145365.35506486893\n",
      "i = 46700/65536\tverts=11300\ttime=145685.85510754585\n",
      "i = 46800/65536\tverts=11399\ttime=145992.20229315758\n",
      "i = 46900/65536\tverts=11499\ttime=146300.70869636536\n",
      "i = 47000/65536\tverts=11596\ttime=146611.07873272896\n",
      "i = 47100/65536\tverts=11696\ttime=146930.18922948837\n",
      "i = 47200/65536\tverts=11707\ttime=147232.86593866348\n",
      "i = 47300/65536\tverts=11714\ttime=147532.1147222519\n",
      "i = 47400/65536\tverts=11729\ttime=147831.870169878\n",
      "i = 47500/65536\tverts=11741\ttime=148140.70892477036\n",
      "i = 47600/65536\tverts=11750\ttime=148441.241584301\n",
      "i = 47700/65536\tverts=11765\ttime=148739.45348715782\n",
      "i = 47800/65536\tverts=11776\ttime=149038.21963453293\n",
      "i = 47900/65536\tverts=11790\ttime=149343.40211105347\n",
      "i = 48000/65536\tverts=11803\ttime=149647.1158530712\n",
      "i = 48100/65536\tverts=11813\ttime=149947.5034635067\n",
      "i = 48200/65536\tverts=11835\ttime=150250.42150115967\n",
      "i = 48300/65536\tverts=11853\ttime=150540.39211511612\n",
      "i = 48400/65536\tverts=11864\ttime=150836.35732221603\n",
      "i = 48500/65536\tverts=11884\ttime=151142.96723985672\n",
      "i = 48600/65536\tverts=11899\ttime=151451.3451912403\n",
      "i = 48700/65536\tverts=11912\ttime=151743.87130475044\n",
      "i = 48800/65536\tverts=11932\ttime=152032.52027988434\n",
      "i = 48900/65536\tverts=11943\ttime=152324.2926785946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 49000/65536\tverts=11961\ttime=152627.6687707901\n",
      "i = 49100/65536\tverts=11977\ttime=152932.67748308182\n",
      "i = 49200/65536\tverts=11998\ttime=153226.7618534565\n",
      "i = 49300/65536\tverts=12029\ttime=153518.14371919632\n",
      "i = 49400/65536\tverts=12060\ttime=153826.40931868553\n",
      "i = 49500/65536\tverts=12094\ttime=154133.5251071453\n",
      "i = 49600/65536\tverts=12125\ttime=154442.6230957508\n",
      "i = 49700/65536\tverts=12159\ttime=154747.76614904404\n",
      "i = 49800/65536\tverts=12188\ttime=155040.4963645935\n",
      "i = 49900/65536\tverts=12220\ttime=155337.50387215614\n",
      "i = 50000/65536\tverts=12252\ttime=155631.7814874649\n",
      "i = 50100/65536\tverts=12282\ttime=155927.15117931366\n",
      "i = 50200/65536\tverts=12314\ttime=156233.93265509605\n",
      "i = 50300/65536\tverts=12325\ttime=156569.09540748596\n",
      "i = 50400/65536\tverts=12335\ttime=156893.60634493828\n",
      "i = 50500/65536\tverts=12357\ttime=157220.07145881653\n",
      "i = 50600/65536\tverts=12374\ttime=157535.17072701454\n",
      "i = 50700/65536\tverts=12393\ttime=157858.68368148804\n",
      "i = 50800/65536\tverts=12420\ttime=158180.27321600914\n",
      "i = 50900/65536\tverts=12445\ttime=158502.82131695747\n",
      "i = 51000/65536\tverts=12472\ttime=158822.43960404396\n",
      "i = 51100/65536\tverts=12489\ttime=159137.14923501015\n",
      "i = 51200/65536\tverts=12512\ttime=159459.31213450432\n",
      "i = 51300/65536\tverts=12529\ttime=159759.10913658142\n",
      "i = 51400/65536\tverts=12546\ttime=160049.13441491127\n",
      "i = 51500/65536\tverts=12556\ttime=160356.76318764687\n",
      "i = 51600/65536\tverts=12578\ttime=160665.9351351261\n",
      "i = 51700/65536\tverts=12590\ttime=160967.13955044746\n",
      "i = 51800/65536\tverts=12606\ttime=161267.7349638939\n",
      "i = 51900/65536\tverts=12625\ttime=161565.55323958397\n",
      "i = 52000/65536\tverts=12635\ttime=161853.8113231659\n",
      "i = 52100/65536\tverts=12656\ttime=162160.08910894394\n",
      "i = 52200/65536\tverts=12668\ttime=162460.51343131065\n",
      "i = 52300/65536\tverts=12683\ttime=162756.81511497498\n",
      "i = 52400/65536\tverts=12694\ttime=163064.58086776733\n",
      "i = 52500/65536\tverts=12702\ttime=163363.87898540497\n",
      "i = 52600/65536\tverts=12710\ttime=163664.39522123337\n",
      "i = 52700/65536\tverts=12719\ttime=163968.14862513542\n",
      "i = 52800/65536\tverts=12729\ttime=164264.38441848755\n",
      "i = 52900/65536\tverts=12739\ttime=164579.0940475464\n",
      "i = 53000/65536\tverts=12749\ttime=164887.64312291145\n",
      "i = 53100/65536\tverts=12761\ttime=165197.05495119095\n",
      "i = 53200/65536\tverts=12775\ttime=165507.3651971817\n",
      "i = 53300/65536\tverts=12781\ttime=165835.5686109066\n",
      "i = 53400/65536\tverts=12784\ttime=166173.7596027851\n",
      "i = 53500/65536\tverts=12787\ttime=166508.73010849953\n",
      "i = 53600/65536\tverts=12792\ttime=166838.92639279366\n",
      "i = 53700/65536\tverts=12797\ttime=167159.32129502296\n",
      "i = 53800/65536\tverts=12805\ttime=167486.36410093307\n",
      "i = 53900/65536\tverts=12820\ttime=167811.31952285767\n",
      "i = 54000/65536\tverts=12835\ttime=168137.72335791588\n",
      "i = 54100/65536\tverts=12841\ttime=168470.484801054\n",
      "i = 54200/65536\tverts=12847\ttime=168788.14840006828\n",
      "i = 54300/65536\tverts=12854\ttime=169098.26495075226\n",
      "i = 54400/65536\tverts=12863\ttime=169399.3644528389\n",
      "i = 54500/65536\tverts=12870\ttime=169709.49409747124\n",
      "i = 54600/65536\tverts=12886\ttime=170010.19934368134\n",
      "i = 54700/65536\tverts=12897\ttime=170317.91697335243\n",
      "i = 54800/65536\tverts=12909\ttime=170606.83810520172\n",
      "i = 54900/65536\tverts=12920\ttime=170902.88964772224\n",
      "i = 55000/65536\tverts=12931\ttime=171205.58755421638\n",
      "i = 55100/65536\tverts=12949\ttime=171510.5930826664\n",
      "i = 55200/65536\tverts=12961\ttime=171819.1356215477\n",
      "i = 55300/65536\tverts=12980\ttime=172122.00084972382\n",
      "i = 55400/65536\tverts=13075\ttime=172425.5698208809\n",
      "i = 55500/65536\tverts=13173\ttime=172732.86438035965\n",
      "i = 55600/65536\tverts=13273\ttime=173049.62579798698\n",
      "i = 55700/65536\tverts=13368\ttime=173366.6260354519\n",
      "i = 55800/65536\tverts=13467\ttime=173671.34798932076\n",
      "i = 55900/65536\tverts=13567\ttime=173975.8042526245\n",
      "i = 56000/65536\tverts=13664\ttime=174290.54324889183\n",
      "i = 56100/65536\tverts=13764\ttime=174603.00432157516\n",
      "i = 56200/65536\tverts=13858\ttime=174915.96227025986\n",
      "i = 56300/65536\tverts=13958\ttime=175209.96686458588\n",
      "i = 56400/65536\tverts=13982\ttime=175528.87707090378\n",
      "i = 56500/65536\tverts=13986\ttime=175856.13904619217\n",
      "i = 56600/65536\tverts=13990\ttime=176192.8887681961\n",
      "i = 56700/65536\tverts=13994\ttime=176511.43165659904\n",
      "i = 56800/65536\tverts=13996\ttime=176840.29510641098\n",
      "i = 56900/65536\tverts=14004\ttime=177241.13409376144\n",
      "i = 57000/65536\tverts=14014\ttime=177604.54691147804\n",
      "i = 57100/65536\tverts=14020\ttime=177967.7568976879\n",
      "i = 57200/65536\tverts=14026\ttime=178330.64229893684\n",
      "i = 57300/65536\tverts=14031\ttime=178694.0444097519\n",
      "i = 57400/65536\tverts=14041\ttime=179058.83904075623\n",
      "i = 57500/65536\tverts=14054\ttime=179422.7922167778\n",
      "i = 57600/65536\tverts=14068\ttime=179787.8529741764\n",
      "i = 57700/65536\tverts=14076\ttime=180152.97108387947\n",
      "i = 57800/65536\tverts=14083\ttime=180518.3006989956\n",
      "i = 57900/65536\tverts=14088\ttime=180882.5745830536\n",
      "i = 58000/65536\tverts=14090\ttime=181245.54612350464\n",
      "i = 58100/65536\tverts=14093\ttime=181608.7410197258\n",
      "i = 58200/65536\tverts=14098\ttime=181973.517714262\n",
      "i = 58300/65536\tverts=14103\ttime=182338.08047914505\n",
      "i = 58400/65536\tverts=14110\ttime=182694.06223893166\n",
      "i = 58500/65536\tverts=14124\ttime=183029.49118828773\n",
      "i = 58600/65536\tverts=14134\ttime=183365.9976298809\n",
      "i = 58700/65536\tverts=14142\ttime=183701.7530119419\n",
      "i = 58800/65536\tverts=14149\ttime=184038.29783177376\n",
      "i = 58900/65536\tverts=14158\ttime=184373.65018987656\n",
      "i = 59000/65536\tverts=14167\ttime=184709.28336405754\n",
      "i = 59100/65536\tverts=14179\ttime=185044.3215367794\n",
      "i = 59200/65536\tverts=14190\ttime=185380.88648486137\n",
      "i = 59300/65536\tverts=14205\ttime=185717.1696987152\n",
      "i = 59400/65536\tverts=14214\ttime=186053.35311365128\n",
      "i = 59500/65536\tverts=14223\ttime=186385.21335363388\n",
      "i = 59600/65536\tverts=14241\ttime=186716.7727329731\n",
      "i = 59700/65536\tverts=14250\ttime=187047.55621099472\n",
      "i = 59800/65536\tverts=14267\ttime=187380.00235652924\n",
      "i = 59900/65536\tverts=14280\ttime=187710.90963625908\n",
      "i = 60000/65536\tverts=14289\ttime=188044.35176801682\n",
      "i = 60100/65536\tverts=14301\ttime=188377.41016292572\n",
      "i = 60200/65536\tverts=14309\ttime=188708.6236524582\n",
      "i = 60300/65536\tverts=14321\ttime=189042.39632606506\n",
      "i = 60400/65536\tverts=14334\ttime=189373.96068835258\n",
      "i = 60500/65536\tverts=14345\ttime=189727.6636238098\n",
      "i = 60600/65536\tverts=14354\ttime=190084.55584692955\n",
      "i = 60700/65536\tverts=14366\ttime=190442.00486898422\n",
      "i = 60800/65536\tverts=14379\ttime=190798.48508667946\n",
      "i = 60900/65536\tverts=14387\ttime=191156.62996268272\n",
      "i = 61000/65536\tverts=14399\ttime=191513.17857170105\n",
      "i = 61100/65536\tverts=14412\ttime=191868.7763314247\n",
      "i = 61200/65536\tverts=14422\ttime=192225.9609413147\n",
      "i = 61300/65536\tverts=14436\ttime=192582.63206648827\n",
      "i = 61400/65536\tverts=14443\ttime=192942.09589791298\n",
      "i = 61500/65536\tverts=14467\ttime=193284.2884941101\n",
      "i = 61600/65536\tverts=14499\ttime=193617.69232416153\n",
      "i = 61700/65536\tverts=14530\ttime=193952.83162522316\n",
      "i = 61800/65536\tverts=14563\ttime=194285.42879772186\n",
      "i = 61900/65536\tverts=14595\ttime=194617.89612555504\n",
      "i = 62000/65536\tverts=14629\ttime=194950.76885437965\n",
      "i = 62100/65536\tverts=14658\ttime=195283.03376674652\n",
      "i = 62200/65536\tverts=14688\ttime=195615.65509152412\n",
      "i = 62300/65536\tverts=14720\ttime=195947.64180660248\n",
      "i = 62400/65536\tverts=14755\ttime=196280.1869354248\n",
      "i = 62500/65536\tverts=14778\ttime=196611.80514764786\n",
      "i = 62600/65536\tverts=14800\ttime=196942.12059903145\n",
      "i = 62700/65536\tverts=14813\ttime=197272.42866921425\n",
      "i = 62800/65536\tverts=14829\ttime=197603.2695901394\n",
      "i = 62900/65536\tverts=14847\ttime=197933.31942296028\n",
      "i = 63000/65536\tverts=14856\ttime=198264.4437365532\n",
      "i = 63100/65536\tverts=14878\ttime=198595.49543595314\n",
      "i = 63200/65536\tverts=14891\ttime=198925.83573436737\n",
      "i = 63300/65536\tverts=14906\ttime=199256.053866148\n",
      "i = 63400/65536\tverts=14925\ttime=199587.40607619286\n",
      "i = 63500/65536\tverts=14936\ttime=199922.55829405785\n",
      "i = 63600/65536\tverts=14940\ttime=200286.81443929672\n",
      "i = 63700/65536\tverts=14944\ttime=200651.5843243599\n",
      "i = 63800/65536\tverts=14950\ttime=201015.6766729355\n",
      "i = 63900/65536\tverts=14951\ttime=201379.50845694542\n",
      "i = 64000/65536\tverts=14957\ttime=201743.58871269226\n",
      "i = 64100/65536\tverts=14966\ttime=202106.84907126427\n",
      "i = 64200/65536\tverts=14974\ttime=202469.28640174866\n",
      "i = 64300/65536\tverts=14978\ttime=202831.9938070774\n",
      "i = 64400/65536\tverts=14983\ttime=203196.31852793694\n",
      "i = 64500/65536\tverts=14988\ttime=203559.62447452545\n",
      "i = 64600/65536\tverts=15076\ttime=203902.88117909431\n",
      "i = 64700/65536\tverts=15175\ttime=204243.79635548592\n",
      "i = 64800/65536\tverts=15275\ttime=204586.55648207664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i = 64900/65536\tverts=15375\ttime=204925.15432286263\n",
      "i = 65000/65536\tverts=15472\ttime=205268.48317170143\n",
      "i = 65100/65536\tverts=15567\ttime=205605.23093509674\n",
      "i = 65200/65536\tverts=15656\ttime=205938.86098003387\n",
      "i = 65300/65536\tverts=15751\ttime=206275.19729804993\n",
      "i = 65400/65536\tverts=15848\ttime=206612.5327425003\n",
      "i = 65500/65536\tverts=15942\ttime=206949.18040013313\n",
      "i = 65536/65536\tverts=15978\ttime=207071.59475588799\n"
     ]
    }
   ],
   "source": [
    "temp = multiplyTrops(newFterms[0], newFterms[-1])\n",
    "ws, goodIndices = computeWs(temp, k=min(1000, temp.shape[0]-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
